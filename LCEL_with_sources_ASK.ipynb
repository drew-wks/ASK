{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes Langchain v.0.3.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet langchain-openai\n",
    "# %pip install langchain-qdrant\n",
    "# % pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langsmith\n",
    "accessible [here](https://smith.langchain.com/o/3941ecea-6957-508c-9f4f-08ed62dc7d61/projects/p/0aea481f-080e-45eb-bae1-2ae8ee246bd9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGSMITH CONFIG\n",
    "#\n",
    "# These have to be set as environmental variables to be accessed behind the scenes\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "env_path = find_dotenv()\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = st.secrets[\"LANGCHAIN_TRACING_V2\"]\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = st.secrets[\"LANGCHAIN_PROJECT\"]\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = st.secrets[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ASK_main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for langchain_openai.OpenAIEmbeddings\n",
    "OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]\n",
    "# open_api_key = st.secrets[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "# from langchain.vectorstores import Qdrant Deprecated\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # langchain. No longer needs the API key parameter in 0.3.4\n",
    "    # install ``langchain_openai`` and set``OPENAI_API_KEY`\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"embedding_dims\": 1536,\n",
    "    \"search_type\": \"mmr\",\n",
    "    \"k\": 5,\n",
    "    'fetch_k': 20,   # fetch 30 docs then select 4\n",
    "    'lambda_mult': .7,    # 0= max diversity, 1 is min. default is 0.5\n",
    "    \"score_threshold\": 0.5,\n",
    "    \"model\": \"gpt-3.5-turbo-16k\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"chain_type\": \"stuff\",  # a LangChain parameter\n",
    "}\n",
    "\n",
    "qdrant_collection_name = \"ASK_vectorstore\"\n",
    "qdrant_path = \"/tmp/local_qdrant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "# keep outside the function so it's accessible elsewhere in this notebook\n",
    "llm = ChatOpenAI(model=config[\"model\"], temperature=config[\"temperature\"])\n",
    "query = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def get_retriever():\n",
    "    '''Creates and caches the document retriever and Qdrant client.'''\n",
    "\n",
    "    client = QdrantClient(\n",
    "        url=st.secrets[\"QDRANT_URL\"],\n",
    "        prefer_grpc=True,\n",
    "        api_key=st.secrets[\"QDRANT_API_KEY\"]\n",
    "    )  # cloud instance\n",
    "    # client = QdrantClient(path=\"/tmp/local_qdrant\" )  # local instance: /private/tmp/local_qdrant\n",
    "\n",
    "# Qdrant is deprecated. Use this instead. Notice embedding is singular\n",
    "    qdrant = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=qdrant_collection_name,\n",
    "        embedding=config[\"embedding\"]\n",
    "    )\n",
    "\n",
    "    retriever = qdrant.as_retriever(\n",
    "        search_type=config[\"search_type\"],\n",
    "        search_kwargs={'k': config[\"k\"], \"fetch_k\": config[\"fetch_k\"],\n",
    "                       \"lambda_mult\": config[\"lambda_mult\"], \"filter\": None},  # filter documents by metadata\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create your optional user question enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 10:36:02.737 No runtime found, using MemoryCacheStorageManager\n",
      "2024-11-08 10:36:02.739 No runtime found, using MemoryCacheStorageManager\n",
      "2024-11-08 10:36:02.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:02.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:02.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:02.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:02.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:03.640 Thread 'ThreadPoolExecutor-354_0': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:03.641 Thread 'ThreadPoolExecutor-354_0': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:03.642 Thread 'ThreadPoolExecutor-354_0': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:03.643 Thread 'ThreadPoolExecutor-354_0': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 10:36:03.643 Thread 'ThreadPoolExecutor-354_0': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is required to wear the VE insignia?',\n",
       " 'context': [Document(metadata={'page': 3, 'source': 'For_injestion/Copy_of_2023_VE_workshop_Dec_4_22__2_.pdf_compressed.pdf', '_id': '30f44f38-fd3d-4def-ae3a-ba3c8b13df75', '_collection_name': 'ASK_vectorstore'}, page_content='Approved Vessel Examiner Uniforms\\n•Power Squadron’s VEs wear the USPS or America’s \\nBoating Club VE Polo shirt (red) with tan or khaki \\ncolored pants (long or short). \\n•Auxiliary VEs may wear the ODU, Alternate Working \\nUniform, or Hot Weather uniforms. \\n•The Auxiliary VE Polo shirt (blue/white) is \\nauthorized for wear as an optional uniform shirt \\nworn as part of the ODU or Hot Weather uniform. \\n•VE’s should always wear a life jacket during a Vessel \\nSafety Check\\n4\\n•VE’s required to wear a life jacket when the VSC is taking place on/around \\nthe water, and encouraged to do so in classrooms, to model the behavior \\nwe want from our fellow boaters.\\n•The VE Polo shirt is not authorized for wearing as a stand alone item with \\ncivilian clothing or on patrol, and no insignia, name tag, or breast device \\nshall be worn with the shirt. \\n•Headgear (e.g. covers) (when wearing the Polo shirt) the Auxiliary staff \\noffice insignia shall not display.  Only the member device shall be displayed \\non the headgear.\\n•Forward any questions and comments that you have up the chain of \\nleadership.\\n(NEXT SLIDE)\\n4'),\n",
       "  Document(metadata={'page': 107, 'source': 'References/Gold Side/Not Auxiliary Specific/Uniform Regulations CIM_1020_6K.PDF', '_id': '74fa221b-9c92-4b72-955f-7f4caca0bcd5', '_collection_name': 'ASK_vectorstore'}, page_content='COMDTINST M1020.6K  \\n \\n  4-11 Standard Ball Cap  and Unit Ball Cap  \\n \\nThe insignia worn on the ball cap will be the 1.25 inch \\nGarrison cap rank insignia  for all E -7 to E-10, while E -4 \\nto E-6 and Officers shall wear the 1 inch standard collar \\ninsignia .  All insignia will be centered on the front of the \\ncap so as to not interfere with the lettering .  Standard Ball \\nCap - Centered between the lettering and the bill of the \\ncap.  Unit Ball Cap - Centered between the lettering \\nabove and lettering below .  O-6 insignia is worn with the \\neagle facing the wearer’s right.  \\n \\nBrims shall have a natural curve.  Flat or creased brims are \\nnot authorized.   \\n \\n       \\n  \\nCold Weather Cap  \\n \\nThe insignia worn on the Cold Weather Cap will be the \\nstandard metal Combination Cap insignia.  All insignia \\nwill be centered on the front of the cap using the attached \\ngrommet hole .   \\n   \\n  \\n \\n \\n4.A.5.  Enlisted Rate/Pay Grade  Insignia  \\n \\nEnlisted rate/pay grade  insignia consist of  embroidered and  metal collar insignia and \\nembroidered sleeve markings.  All insignia will be machine or hand -stitched in place \\nusing thread the color of the uniform with a minimum of six stitches per inch.  Collar \\ninsignia will consist of metal or embroidered collar insignia indicating the wearer’s \\nrate/pay grade.  There will be no mixing of the two types of collar insignia.  The insignia \\nis worn on both collars of all uniform shirts, except for th e white dress shirt.  \\n \\nDuring wartime or other emergency conditions, the senior officer present may require \\nsubdued insignia for all personnel when the wearing of normal metal bright finish \\ninsignia would be considered hazardous.  \\n \\nAlthough, metal collar ins ignia are standard, embroidered sew -on cloth collar insignia are \\nstandard on the Operational Dress Uniform (ODU) only.'),\n",
       "  Document(metadata={'page': 472, 'source': 'References/Auxiliary Manual CIM_16790_1G.pdf', '_id': '36f4039b-45c3-434e-b467-77d1edd4de8e', '_collection_name': 'ASK_vectorstore'}, page_content='COMDTINST M16790.1G \\n \\n \\n \\n \\n \\n Although time requirements are detailed fo r the permanent insignia, there are \\nno time requirements detailed for the te mporary version.  However, the same \\nconvention applies for the temporary in signia.  Temporary entitlement based \\non six months and completion of qualific ation equates to one day per week \\nfor six months for an Auxiliarist to earn  the temporary insignia.  This level of \\neffort shall be required in order to continue wearing th e temporary insignia \\nuntil the permanent insignia is earned.  If an Auxiliarist is unable to provide \\nthat level of effort, for any reason, th e temporary insignia shall be removed.  \\nSupport of a boat forces unit is the primar y requirement to earn this insignia.  \\nThis means direct support as define d in the Coast Guard BOAT Manual, \\nVolume I, COMDTINST M16114.32 (series) .  Standard Auxiliary surface \\npatrols do not count for such.  For ma nner of wear, refer to Coast Guard \\nUniform Regulations, COMDTINST M1020.6 (series).  (see Figure 10-16 ) \\n \\n  \\nFigure 10-16 \\nBoat Force Operations Insignia \\nF.9.j.  Miniature \\nDevices Miniature devices may only be wo rn on Dinner Dress uniforms.  Auxiliarist s \\nmay wear the AUXOP and past offi cer devices on all uniforms.  \\nF.9.k.  Other \\nDevices and \\nPatches Auxiliarists may wear only two breast de vices at one time and these are worn \\non the uniform’s left side only.  Ot her authorized devi ces include those \\nearned during U.S. military service, such as the combat infantryman and \\nmedic devices, aviation wings, Air Fo rce specialty badges, Pathfinder, \\nairborne and air assault badges, submariner dolphins, Surface Warfare \\nOfficer, etc.  The wearer may select any two and determin e their precedence \\n(normally, the higher precedence is placed on the insignia that represents the \\nmost program time).  Auxiliarist s wear the first device on the left centered \\ndirectly above the ribbons or miniature medals.  Auxiliarist s wear the second \\ndevice centered on the pocket flap immediately below the ribbons or \\nminiature medals.  For example, wearing Auxiliary aviator wings centered on \\nthe left, above the ribbons, and an Auxiliary coxswain insignia centered \\nbelow the ribbons.  Sew-on patches, strips, Auxiliary unit designations, \\nhonor guard, ranger, special forces, and other cloth patches, not otherwise \\napproved for wear, are not authorized on the Auxiliary uniform.  \\n10-49  '),\n",
       "  Document(metadata={'page': 2, 'source': 'References/ALAUXs/2018/03_18_AUXILIARY_RECIPROCITY_WITH_U.S._POWER_SQUADRONS_FOR_VESSEL_EXAMINER_AND_INSTRUCTOR_COMPETENCIES___01FEB2018.pdf', '_id': '616265ad-b6a7-4b2b-b7b1-16a611fbc7eb', '_collection_name': 'ASK_vectorstore'}, page_content=\"3 \\n 7.  This reciprocity only pertains to each organization's VE and IT competencies.   All other \\nrespective membership requirements for each organization must be met.   For example, a \\nUSPS VE who joins the Auxiliary must  undergo the Auxiliary background check process, \\nhave completed an approved boating safety course, and have completed Auxiliary Mandated \\nTraining in order to conduct VSCs as an Auxiliarist.  \\n8.  These provisions shall be appropriately incorporated in any Co ast Guard Auxiliary VE or \\nIT program material revisions, and shall be memorialized in the next changes to the relevant \\nCoast Guard Auxiliary program's Commandant instructions and manuals.   \\n9.  The purpose of this list is to keep Auxiliarists as well as all  other interested parties abreast \\nof current developments, policies, manuals, etc. All information contained herein and linked is \\nOFFICIAL policy and Information.  \\n10. Internet Release and Distribution is Authorized.\"),\n",
       "  Document(metadata={'page': 514, 'source': 'References/Auxiliary Manual CIM_16790_1G.pdf', '_id': '47fc7b37-dc47-43df-b094-1de0b37c3a4a', '_collection_name': 'ASK_vectorstore'}, page_content='COMDTINST M16790.1G \\n \\n \\n \\n \\n \\nI.3.h.  Insignia Full silver sleev e lace is worn on the coat slee ves mounted by the appropriate \\nAuxiliary shield and soft or enhanced shoulder boards are worn on the shirt. \\nI.3.i.  Breast \\nInsignia/Devices This uniform is worn with ribbons, breast insignia, ba dges, devices, and \\nname tags. \\nI.3.j.  Hat The combination cap is the prescribed ha t to be worn with this uniform.  The \\ngarrison cap may be worn, but it will no longer be authorized for Auxiliary \\nwear with the Service Dress Blue uniform as of 31 December 2012.  The \\ncold weather cap may be worn in accordance with the provisions of section \\nD.3.e of this chapter.  \\nI.3.k.  \\nAccessories The bridge coat and the trench coat ar e the prescribed outer wear with this \\nuniform. \\nThe over coat, reefer coat, and foul weather parka may be worn with the \\nService Dress Blue uniform, but they  w i l l  n o  l o n g e r  b e  a u t h o r i z e d  f o r  \\nAuxiliary wear with it as of 31 D ecember 2012.  The windbreaker may be \\nworn in place of the Service Dress Blue coat, unless the coat is prescribed or \\nconsidered more appropriate.  The cardigan sweater and the wooly-pully \\nsweater may be worn with this uniform in accordance with the provisions of \\nsection D.6 and D.7 of this chapter.  \\n10-91')],\n",
       " 'answer': {'answer': \"To wear the Vessel Examiner insignia, the individual must be a qualified Vessel Examiner and meet the uniform regulations. The approved uniforms for Vessel Examiners include the USPS or America's Boating Club VE Polo shirt (red) with tan or khaki colored pants (long or short) for Power Squadron's VEs, and the ODU, Alternate Working Uniform, or Hot Weather uniforms for Auxiliary VEs. The Auxiliary VE Polo shirt (blue/white) is authorized as an optional uniform shirt worn as part of the ODU or Hot Weather uniform. It is important to note that the VE Polo shirt is not authorized for wearing as a stand-alone item with civilian clothing or on patrol. When conducting Vessel Safety Checks, Vessel Examiners are required to wear a life jacket when the check is taking place on or around the water, and they are encouraged to do so in classrooms to model the behavior for fellow boaters. Headgear worn with the Polo shirt should not display the Auxiliary staff office insignia, only the member device. For specific regulations and requirements, it is recommended to refer to the Coast Guard Uniform Regulations (COMDTINST M1020.6K).\",\n",
       "  'sources': ['Coast Guard Uniform Regulations (COMDTINST M1020.6K)']}}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define schema for response\n",
    "class AnswerWithSources(TypedDict):\n",
    "    \"\"\"An answer to the question, with sources.\"\"\"\n",
    "    answer: str\n",
    "    sources: Annotated[\n",
    "        List[str],\n",
    "        ...,\n",
    "        \"List of sources and pages used to answer the question\",\n",
    "    ]\n",
    "\n",
    "\n",
    "# Cache data retrieval function\n",
    "@st.cache_data\n",
    "def get_retrieval_context(file_path: str):\n",
    "    '''Reads the worksheets Excel file into a dictionary of dictionaries.'''\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    context_dict = {}\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        if df.shape[1] >= 2:\n",
    "            context_dict[sheet_name] = pd.Series(\n",
    "                df.iloc[:, 1].values, index=df.iloc[:, 0]).to_dict()\n",
    "    return context_dict\n",
    "\n",
    "\n",
    "# Cache the prompt creation\n",
    "@st.cache_resource\n",
    "def create_prompt():\n",
    "    system_prompt = (\n",
    "        \"Use the following pieces of context to answer the users question. \"\n",
    "        \"INCLUDES ALL OF THE DETAILS IN YOUR RESPONSE, INDLUDING REQUIREMENTS AND REGULATIONS. \"\n",
    "        \"National Workshops are required for boat crew, aviation, and telecommunications when they are offered. \"\n",
    "        \"Include Auxiliary Core Training (AUXCT) for questions on certifications or officer positions. \"\n",
    "        \"If you don't know the answer, just say I don't know. \\n----------------\\n{context}\"\n",
    "    )\n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "\n",
    "\n",
    "# Cache enrichment function to use cached context\n",
    "@st.cache_data\n",
    "def enrich_question_via_code(user_question: str) -> str:\n",
    "    retrieval_context_dict = get_retrieval_context(\n",
    "        'config/retrieval_context.xlsx')\n",
    "    acronyms_dict = retrieval_context_dict.get(\"acronyms\", {})\n",
    "    terms_dict = retrieval_context_dict.get(\"terms\", {})\n",
    "\n",
    "    enriched_question = user_question\n",
    "    for acronym, full_form in acronyms_dict.items():\n",
    "        if pd.notna(acronym) and pd.notna(full_form):\n",
    "            enriched_question = re.sub(\n",
    "                r'\\b' + re.escape(str(acronym)) + r'\\b', str(full_form), enriched_question)\n",
    "    for term, explanation in terms_dict.items():\n",
    "        if pd.notna(term) and pd.notna(explanation):\n",
    "            if str(term) in enriched_question:\n",
    "                enriched_question += f\" ({str(explanation)})\"\n",
    "    return enriched_question\n",
    "\n",
    "\n",
    "# Function to format documents (doesn't require caching)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Caching the RAG pipeline setup as a resource\n",
    "@st.cache_resource\n",
    "def create_rag_pipeline():\n",
    "    prompt = create_prompt()\n",
    "    rag_chain_from_docs = (\n",
    "        {\n",
    "            \"input\": lambda x: enrich_question_via_code(x[\"input\"]),\n",
    "            \"context\": lambda x: format_docs(x[\"context\"]),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm.with_structured_output(AnswerWithSources)\n",
    "    )\n",
    "    retrieve_docs = (lambda x: x[\"input\"]) | get_retriever()\n",
    "    return RunnablePassthrough.assign(context=retrieve_docs).assign(answer=rag_chain_from_docs)\n",
    "\n",
    "\n",
    "# RAG invocation\n",
    "def rag(user_question):\n",
    "    chain = create_rag_pipeline()\n",
    "    response = chain.invoke({\"input\": user_question})\n",
    "    return response\n",
    "\n",
    "\n",
    "user_question = \"what is required to wear the VE insignia?\"\n",
    "response = rag(user_question)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the pipeline using LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom LCEL implementation which allows you the option of only returning sources that were actually used in the response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works by building up a dict with the input query,\n",
    "then add the retrieved docs in the `\"context\"` key;\n",
    "Feed both the query and context into a RAG chain and add the result to the dict.\n",
    "\n",
    "We use the model's tool-calling features to generate structured output, consisting of an answer and list of sources. The schema for the response is represented in the `AnswerWithSources` TypedDict, below.\n",
    "We remove the `StrOutputParser()`, as we expect `dict` output in this scenario.\n",
    "Note that `result` is a dict with keys `\"input\"`, `\"context\"`, and `\"answer\"`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THis outputs the model's response as well as the subset of retrieved information that it used to infer its response.\n",
    "\n",
    "Note that the `answer` element in the `response` disctionary is itself a dictionary containing `answer` and `source` keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "user_question = \"How long can someone be VNACO in the Auxiliary?\"\n",
    "user_question = enrich_question_via_code(user_question)\n",
    "retriever = get_retriever()\n",
    "response = chain.invoke({\"input\": user_question})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\n",
    "    {\"input\": user_question})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(response[\"answer\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the response object also contains-- the original query, all the retrieved docs, the LLM response, and the sources used by the model to generate its answer-- we can also list the titles of the retrieved documents and the source page content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    item.page_content\n",
    "    item.metadata['source']\n",
    "    item.metadata['page']\n",
    "'''\n",
    "print(\"Sources:\")\n",
    "for item in response[\"context\"]:\n",
    "    print(\n",
    "        f\"{item.metadata['source']} page {item.metadata['page']}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THis one is formatted in the same way as the short source list in ASK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_list = []\n",
    "\n",
    "for i, doc in enumerate(response['context'], start=1):\n",
    "    page_content = doc.page_content\n",
    "    source = doc.metadata['source']\n",
    "    short_source = source.split('/')[-1].split('.')[0]\n",
    "    page = doc.metadata['page']\n",
    "    markdown_list.append(f\"*{short_source}*, page {page}\\n\")\n",
    "\n",
    "short_source_list = '\\n'.join(markdown_list)\n",
    "print(short_source_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THis one is formatted in the same way as the long source list in ASK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_list = []\n",
    "\n",
    "for i, doc in enumerate(response['context'], start=1):\n",
    "    page_content = doc.page_content\n",
    "    source = doc.metadata['source']\n",
    "    short_source = source.split('/')[-1].split('.')[0]\n",
    "    page = doc.metadata['page']\n",
    "    markdown_list.append(\n",
    "        f\"**Reference {i}:**    *{short_source}*, page {page}   {page_content}\\n\")\n",
    "\n",
    "long_source_list = '\\n'.join(markdown_list)\n",
    "print(long_source_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For reference, here's the full response object. You can see it contains the original query all the retrieved docs, the LLM response, and the sources used by the model to generate its answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
