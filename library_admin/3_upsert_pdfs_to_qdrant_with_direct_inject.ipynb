{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bdf56e",
   "metadata": {},
   "source": [
    "# Upsert PDFs to qdrant\n",
    "#### This is an entire workflow from PDF to RAG.\n",
    "#### It uses a now deprecated version of the langchain qdrant vectorstore object which does not allow for adjustment to metadata during the upsert process. As a result, it relied on a process of adding metadata to the pdfs prior to chunking them. This was less than ideal as the pdf standard adds a '/' to each field which renders them inaccessible as filter keys in Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e257d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-v1/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Confirm you're using the correct interpreter\n",
    "#\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda072",
   "metadata": {},
   "source": [
    "## 0. Installs and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip list # See what's installed and versions\n",
    "# %pip install openai==0.27.8\n",
    "# %pip install langchain==0.0.315\n",
    "# %pip install --upgrade docarray\n",
    "# %pip install python-doten\n",
    "# %pip install --upgrade wandb\n",
    "# %pip install qdrant-client==1.6.3\n",
    "# %pip install pympler==1.1.3\n",
    "# %pip install pypdf==5.0.1\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# required for langchain.embeddings.OpenAIEmbeddings. If this form of the key doesn't work, try OPENAI_API_KEY = st.secrets[\"QDRANT_API_KEY\"]\n",
    "\n",
    "openai.api_key = st.secrets[\"QDRANT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730057d3",
   "metadata": {},
   "source": [
    "## 1. Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5540a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"splitter_type\": \"CharacterTextSplitter\",\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": len,\n",
    "    \"separators\": [\"}\"],  # [\" \", \",\", \"\\n\"]\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"embedding_dims\": 1536,\n",
    "    \"search_type\": \"mmr\",\n",
    "    'fetch_k': 20,   # number of documents to pass to the search alg (eg., mmr)\n",
    "    \"k\": 5,  # number of document from fetch to pass to the LLM for inference\n",
    "    'lambda_mult': .7,    # 0= max diversity, 1 is max relevance. default is 0.5\n",
    "    \"score_threshold\": 0.5,  # for similarity score\n",
    "    \"model\": \"gpt-3.5-turbo-16k\",  # gpt-4, gpt-3.5-turbo-16k\n",
    "    \"temperature\": 0.7,\n",
    "    \"chain_type\": \"stuff\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1eb1f",
   "metadata": {},
   "source": [
    "OPTIONAL: Langchain debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c665ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_collection_name = \"ASK_vectorstore\"\n",
    "# Only required for local instance (actual location is MacHD: private tmp local_qdrant)\n",
    "qdrant_path = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/qdrant\"\n",
    "# qdrant_path = \"/tmp/local_qdrant\"\n",
    "\n",
    "source_directory = \"./raw_pdfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea2a89",
   "metadata": {},
   "source": [
    "## 2. Chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDFs from directory...\n",
      "Processed USCG_Addendum_to_US_NSS_to_IAMSAR-CI_16130_2G-2022-10-01.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pypdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "def extract_metadata_from_pdfs(pdfs_source_dir):\n",
    "    file_list = []\n",
    "    pages = []\n",
    "    total_size = 0\n",
    "\n",
    "    # Check if the path is a directory or a file\n",
    "    if os.path.isdir(pdfs_source_dir):\n",
    "        print(\"Loading PDFs from directory...\")\n",
    "        for foldername, subfolders, filenames in os.walk(pdfs_source_dir):\n",
    "            for file in filenames:\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    process_pdf(os.path.join(foldername, file),\n",
    "                                file_list, pages, total_size)\n",
    "    elif os.path.isfile(pdfs_source_dir) and pdfs_source_dir.lower().endswith('.pdf'):\n",
    "        print(\"Loading a single PDF file...\")\n",
    "        process_pdf(pdfs_source_dir, file_list, pages, total_size)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Error: The path '{pdfs_source_dir}' is not a valid directory or PDF file!\")\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path, file_list, pages, total_size):\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        file_processed = False  # Flag to track if the file has been processed\n",
    "\n",
    "        for doc in documents:\n",
    "            with open(doc.metadata[\"source\"], \"rb\") as pdf_file_obj:\n",
    "                reader = pypdf.PdfReader(pdf_file_obj)\n",
    "                pdf_metadata = reader.metadata\n",
    "                doc.metadata.update(\n",
    "                    {key: pdf_metadata[key] for key in pdf_metadata.keys()})\n",
    "\n",
    "            pages.append(doc)\n",
    "            if not file_processed:\n",
    "                file_list.append(pdf_path.split('/')[-1])\n",
    "                total_size += os.path.getsize(pdf_path)\n",
    "                file_processed = True  # Set flag to True after processing the file\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "\n",
    "    if file_processed:\n",
    "        print(f\"Processed {pdf_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "pages = extract_metadata_from_pdfs(source_directory)\n",
    "if pages:\n",
    "    last_page = pages[-1]\n",
    "else:\n",
    "    print(\"No pages were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab05e49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='U.S. Department of \\nHomeland Security  \\nUnited States \\nCoast Guard\\nU. S. COAST GUARD \\nADDENDUM  \\nTO THE  \\nUNITED STATES  \\nNATIONAL SEARCH AND RESCUE SUPPLEMENT (NSS)  \\nTo The  \\nInternational Aeronautical and Maritime Search and Rescue Manual \\n(IAMSAR)  \\nCOMDTINST 16130.2 G \\nOctober  2022', metadata={'source': './raw_pdfs/USCG_Addendum_to_US_NSS_to_IAMSAR-CI_16130_2G-2022-10-01.pdf', 'page': 0, '/Author': 'USCG', '/CreationDate': \"D:20221028162404-04'00'\", '/Creator': 'Adobe Acrobat Pro DC (32-bit) 22.2.20191', '/Keywords': 'CI_16130_2G_THE U.S. COAST GUARD ADDENDUM TO THE UNITED STATES NATIONAL SEARCH AND RESCUE SUPPLEMENT (NSS) TO THE INTERNATIONAL AERONAUTICAL AND MARITIME SEARCH AND RESCUE MANUAL (IAMSAR)', '/ModDate': \"D:20221102090321-04'00'\", '/Producer': 'Adobe Acrobat Pro DC (32-bit) 22.2.20191', '/Subject': 'CG-5R, (202) 372-2010', '/Title': 'THE U.S. COAST GUARD ADDENDUM TO THE UNITED STATES NATIONAL SEARCH AND RESCUE SUPPLEMENT (NSS) TO THE INTERNATIONAL AERONAUTICAL AND MARITIME SEARCH AND RESCUE MANUAL (IAMSAR), COMDTINST 16130.2G'})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# chunks at the page break\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config[\"chunk_size\"],\n",
    "    chunk_overlap=config[\"chunk_overlap\"],\n",
    "    length_function=config[\"length_function\"],\n",
    "    separators=config[\"separators\"]\n",
    ")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "# concat.pages_to_page(pages) #concatenates all the pages of the pdf into one\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "'''\"chunks\" is a list of objects of the class langchain.schema.document.Document'''\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3fd9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Source folder: ./raw_pdfs\n",
      "        Pages processed: 697\n",
      "        Text splitter: CharacterTextSplitter\n",
      "        Chunk size: 2000 characters\n",
      "        Chunk overlap: 200 characters\n",
      "        Chunks (vectors) created: 698 \n",
      "        Dictionary size: 7.44 MB\n",
      "        Vectorstore tokens: 646289\n",
      "        Estimated memory size (Qdrant): 6.13 MB\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def print_document_load_summary(source_directory):\n",
    "    from pympler import asizeof\n",
    "    import tiktoken\n",
    "\n",
    "    encoding = tiktoken.encoding_for_model(config[\"model\"])\n",
    "    vectorstore_tokens = encoding.encode(str(chunks))\n",
    "    num_vectorestore_tokens = len(vectorstore_tokens)\n",
    "    num_chunks = len(chunks)\n",
    "    # Qudrant's formula is memory_size in bytes = number_of_vectors * vector_dimension * 4 bytes * 1.5\n",
    "    memory_size = num_chunks * config[\"embedding_dims\"] * 4 * 1.5\n",
    "\n",
    "    print(f\"\"\"\n",
    "        Source folder: {source_directory}\n",
    "        Pages processed: {len(pages)}\n",
    "        Text splitter: {config[\"splitter_type\"]}\n",
    "        Chunk size: {config[\"chunk_size\"]} characters\n",
    "        Chunk overlap: {config[\"chunk_overlap\"]} characters\n",
    "        Chunks (vectors) created: {num_chunks} \n",
    "        Dictionary size: {asizeof.asizeof(pages) / (1024 * 1024):.2f} MB\n",
    "        Vectorstore tokens: {num_vectorestore_tokens}\n",
    "        Estimated memory size (Qdrant): {memory_size / (1024 * 1024):.2f} MB\n",
    "    \"\"\")\n",
    "\n",
    "    ''' TODO These variables are now in a function so not accessible.    \n",
    "        Document(s)loaded: {len(file_list)}\n",
    "        Load size: {total_size / (1024 * 1024):.2f} MB\n",
    "        '''\n",
    "\n",
    "\n",
    "print_document_load_summary(source_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b24aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='COAST GUARD AUXILIARY \\nOPERATIONAL EXCELLENCE PROGRAM  \\n \\n \\n \\n \\n       \\n \\n     Handbook 16794.4 \\nMarch  2024' metadata={'source': './raw_pdfs/USCG_Operational_Excellence_Program_Handbook_16794_4.pdf', 'page': 0, '/Author': 'Wyman, Kevin S BMCS', '/Comments': '', '/Company': 'Department of Defense', '/ContentTypeId': '0x010100CB76551212F59C40ACA5AFB2CA9DF8AB', '/CreationDate': \"D:20240302095401-05'00'\", '/Creator': 'Acrobat PDFMaker 23 for Word', '/Keywords': '', '/MediaServiceImageTags': '', '/ModDate': \"D:20240302155800-05'00'\", '/Order': '565000.000000000', '/Producer': 'Adobe PDF Library 23.8.53', '/SourceModified': '', '/Subject': '', '/TemplateUrl': '', '/Title': '', '/URL': ', ', '/_dlc_DocId': '65FQPP6MHWJT-513687613-6591', '/_dlc_DocIdItemGuid': '2f10abfc-926b-49a2-9f1d-8c4d7c4987bc', '/_dlc_DocIdPersistId': '0', '/_dlc_DocIdUrl': 'https://cg.portal.uscg.mil/units/cg731/1.HQ/_layouts/DocIdRedir.aspx?ID=65FQPP6MHWJT-513687613-6591, 65FQPP6MHWJT-513687613-6591', '/xd_ProgID': '', '/xd_Signature': ''}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df429bc",
   "metadata": {},
   "source": [
    "## 3. OPTIONAL: Enrich the chunks with metadata\n",
    "### <span style=\"color:red\">WARNING: Ship this for now. TODO: 1. preserve the page key from the original chunk. 2. Calculate doc_id, check for duplicates in qdrant, and insert into metadata. This calls into question the structure of this notebook which currently splits and chunks the entire pdf folder at once, making this complicated. Maybe reqrite to split and chunk on a per-pdf basis  </span>\n",
    "\n",
    "#### This produces a list of chunks, where each list item is an instane of the `Document` class from `langchain.schema.document`. Each chunk contains the text of the pdf, the metadata of the pdf, and the pdf's id.\n",
    "\n",
    "##### The metadata for the first chunk is `chunks[0].metadata`\n",
    "```python\n",
    "{'source': './raw_pdfs/AUXCA_SOP_005_B__20AUG24_ESIGN.pdf',\n",
    " 'page': 0,\n",
    " '/CreationDate': \"D:20240822072431-04'00'\",\n",
    " '/ModDate': \"D:20240822072431-04'00'\"}\n",
    " ```\n",
    "\n",
    "There will be many chunks for many documents. We'll use the 'source' field in the existing chunk metadata to match with a dictionary of metadata for each pdf. Then we'll replace the metadata in each chunk with the new metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_metadatas_to_insert = {'./raw_pdfs/CI_5400_7G.pdf': {'title': 'ORGANIZATION MANAGEMENT, COMDTINST 5400.7G', 'leadership_scope': '1_National', 'page_count': 37, 'creation_date': '2023-12-01T00:00:00Z', 'effective_date': '2024-11-02T22:04:43Z', 'upsert_date': '2024-11-02T22:04:43Z', 'expiration_date': '2034-11-03T10:04:43Z', 'lifecycle': 'none', 'aux_specific': True, 'public_release': True, 'publication_number': 'none', 'source': 'cgaux.org', 'originator': 'CG-BSX-1', 'curator': 'Hamilton,A', 'pdf_id': '7ea37b80-a7ab-58b1-8cb5-afc1ccee61a5', 'pdf_file_name': 'CI_5400_7G', 'pdf_path': './raw_pdfs/CI_5400_7G.pdf'},\n",
    "                               './raw_pdfs/AUXCA_SOP_005_B__20AUG24_ESIGN.pdf': {'title': 'AUXCA SOP 005 B  20AUG24 ESIGN', 'leadership_scope': '1_National', 'page_count': 30, 'creation_date': '2024-08-22T00:00:00Z', 'effective_date': '2024-11-02T22:04:44Z', 'upsert_date': '2024-11-02T22:04:44Z', 'expiration_date': '2034-11-03T10:04:44Z', 'lifecycle': 'none', 'aux_specific': True, 'public_release': True, 'publication_number': 'none', 'source': 'cgaux.org', 'organization': 'CG-BSX', 'curator': 'Wilkins,CA', 'pdf_id': 'b69af3d6-96ee-5a1b-8a1e-9a6feca305b2', 'pdf_file_name': 'AUXCA_SOP_005_B__20AUG24_ESIGN', 'pdf_path': './raw_pdfs/AUXCA_SOP_005_B__20AUG24_ESIGN.pdf'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aaee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterates through each text chunk, checking if the chunk’s source file path matches a key in dict_of_metadatas_to_insert. If a match is found, it replaces the chunk’s metadata with the comprehensive metadata for that document. If no match exists, it issues a warning indicating missing metadata for that source.\n",
    "\n",
    "for chunk in chunks:\n",
    "    source_path = chunk.metadata.get(\"source\")\n",
    "    if source_path in dict_of_metadatas_to_insert:\n",
    "        # Update the chunk's metadata with the matched metadata dictionary\n",
    "        chunk.metadata = dict_of_metadatas_to_insert[source_path]\n",
    "    else:\n",
    "        print(f\"Warning: No metadata found for {source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfa03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='ORGANIZATION \\nMANAGEMENT \\nCOMDTINST 5400.7G \\nJanuary 2024' metadata={'title': 'ORGANIZATION MANAGEMENT, COMDTINST 5400.7G', 'leadership_scope': '1_National', 'page_count': 37, 'creation_date': '2023-12-01T00:00:00Z', 'effective_date': '2024-11-02T22:04:43Z', 'upsert_date': '2024-11-02T22:04:43Z', 'expiration_date': '2034-11-03T10:04:43Z', 'lifecycle': 'none', 'aux_specific': True, 'public_release': True, 'publication_number': 'none', 'source': 'cgaux.org', 'originator': 'CG-BSX-1', 'curator': 'Hamilton,A', 'pdf_id': '7ea37b80-a7ab-58b1-8cb5-afc1ccee61a5', 'pdf_file_name': 'CI_5400_7G', 'pdf_path': './raw_pdfs/CI_5400_7G.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# check a chunk\n",
    "\n",
    "chunks[0].metadata\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1d5c5",
   "metadata": {},
   "source": [
    "## 4. Add chunks to Qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94f7039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13259725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.qdrant.Qdrant at 0x3cb0c4d50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a langchain vectorstore object\n",
    "# langchain.vectorstores.Qdrant was deprecated since 0.1.2. Works here but legacy\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "qdrant = Qdrant(client=client,\n",
    "                collection_name=qdrant_collection_name,\n",
    "                # embedding here is LC interface to the embedding model\n",
    "                embeddings=config[\"embedding\"],\n",
    "                )\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c16d3a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.qdrant.Qdrant at 0x16556ac90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .from_documents  creates the Qdrant vectorstore object with the documents/chunks, embeddings, and metadata and automatically configures the collection.  It is a Langchain class method used to initialize a new Qdrant instance with a collection of documents all at once.\n",
    "\n",
    "qdrant.from_documents(\n",
    "    chunks,\n",
    "    embedding=config[\"embedding\"],  # yes this is required here too\n",
    "    # path=qdrant_path,  # Only required for local instance\n",
    "    collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "    url=st.secrets[\"QDRANT_URL\"],\n",
    "    api_key=st.secrets[\"QDRANT_API_KEY\"],  # Only required for Qdrant Cloud\n",
    "    # keep this to falsse so you don[t overwrite your collection\n",
    "    force_recreate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=new_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9d64f",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b>CONGRATULATIONS: You're done</b></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937261bc",
   "metadata": {},
   "source": [
    "## OPTIONAL: Create NEW vector store and add documents into it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd43b3e",
   "metadata": {},
   "source": [
    "##THIS DOES NOT CURENTLY INJECT NEW METADATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8c8db",
   "metadata": {},
   "source": [
    "#### Combo Create + Add Docs\n",
    "\n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing Qdrant collection</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "\n",
    "def create_localdb_and_add_chunks():\n",
    "    \"\"\"Use only to create the vectore db and load docs the first time. \n",
    "\n",
    "    .from_documents  creates the Qdrant vectorstore object with the documents/chunks, embeddings, and metadata and automatically configures the collection.  It is a Langchain class method used to initialize a new Qdrant instance with a collection of documents all at once.\n",
    "\n",
    "    It overcomes limitations in Langchain by releaseing the vecDB afterwards\"\"\"\n",
    "\n",
    "    client = QdrantClient()\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=qdrant_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "    qdrant.from_documents(\n",
    "        chunks,\n",
    "        embedding=config[\"embedding\"],  # yes this is required here too\n",
    "        path=qdrant_path,  # Only required for local instance\n",
    "        collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "        # url=os.environ.get(\"QDRANT_URL\"),\n",
    "        # Only required for Qdrant Cloud\n",
    "        # api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    "        force_recreate=False,  # don't use if db doesn't already exist\n",
    "    )\n",
    "    # print(client.get_collections())\n",
    "    # print(\n",
    "    # f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")\n",
    "\n",
    "\n",
    "check_me = create_localdb_and_add_chunks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed726a9b",
   "metadata": {},
   "source": [
    "#### Create new Qdrant DB / Collection.\n",
    "\n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing Qdrant collection</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may not work\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "client = QdrantClient(\n",
    "    path=qdrant_path\n",
    ")  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=new_collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "# You may need to delete the lock file to access this afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24657b",
   "metadata": {},
   "source": [
    "#### Add Documents with Timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def add_chunks_to_existingdb_with_delay(batch_size, delay):\n",
    "    \"\"\"\n",
    "    Use only to create the vectore db and load docs the first time. (7min)\n",
    "    This version loads the chunks into the vector store with a delay.\n",
    "\n",
    "    Unlike .from_documents, which is a class method of Qdrant, \n",
    "    this uses  .add_documents which is an instance method of DocArrayInMemorySearch.\n",
    "    This means you have to set up th Qdrant instance first before using it. \n",
    "    By separating the two we can insert a timer delay. It releases the vecDB afterwards.\n",
    "\n",
    "    USAGE: Aim for ~800K tokens and then have the timer delay until 60 sec is reached\n",
    "    \"\"\"\n",
    "\n",
    "    from qdrant_client import QdrantClient\n",
    "    from langchain.vectorstores import Qdrant\n",
    "\n",
    "    client = QdrantClient(\n",
    "        path=qdrant_path\n",
    "    )  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=new_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "\n",
    "    # generate indices starting from 0. increment by batch_size until len(chunks)\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]  # Create a batch of chunks\n",
    "        qdrant.add_documents(documents=batch)  # Add the batch of chunks\n",
    "        # pause time probably don't need to be changed since tokens usually hit limit by 18 sec.\n",
    "        time.sleep(delay)\n",
    "\n",
    "    del qdrant\n",
    "    client.close()    # Release the database from this process\n",
    "    del client\n",
    "\n",
    "\n",
    "add_chunks_to_existingdb_with_delay(1700, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1c0a3",
   "metadata": {},
   "source": [
    "## 5. Connect to Vector Store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cdedd8",
   "metadata": {},
   "source": [
    "#### Init Qdrant Cloud service entrypoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f09d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "del qdrant\n",
    "client.close()    # Release the database from this process\n",
    "del client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "\n",
    "if 'client' not in globals():\n",
    "    client = QdrantClient(url=st.secrets[\"QDRANT_URL\"],  # for local instance substitute (path=qdrant_path)\n",
    "                          api_key=st.secrets[\"QDRANT_API_KEY\"])  # not needed for local instance\n",
    "else:\n",
    "    print(f\"Client already exists at {client}\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b37d60",
   "metadata": {},
   "source": [
    "### Confirm client is initialized and location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.local.qdrant_local import QdrantLocal\n",
    "from qdrant_client.qdrant_remote import QdrantRemote\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check if the client is running locally or via a URL\n",
    "    if isinstance(client._client, QdrantLocal):\n",
    "        print(\"The client is running locally.\")\n",
    "    elif isinstance(client._client, QdrantRemote):\n",
    "        print(\"The client is running via a URL.\")\n",
    "    else:\n",
    "        # This else block handles cases where client._client is neither QdrantLocal nor QdrantRemote\n",
    "        print(\"Unable to determine the running mode of the Qdrant client.\")\n",
    "except Exception as e:\n",
    "    # This block catches any other exceptions that might occur\n",
    "    print(\"Unable to determine the running mode of the Qdrant client. Error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "\n",
    "qdrant = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=qdrant_collection_name,\n",
    "    # embedding here is a LC interface to the embedding model,\n",
    "    embeddings=config[\"embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f01bb",
   "metadata": {},
   "source": [
    "## 6. Initialize a Document Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a VectorStoreRetriever called retriever from the LC qdrant vector store object\n",
    "\n",
    "# Option 1 using MMR search\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': config[\"k\"], \"fetch_k\": config[\"fetch_k\"],\n",
    "                   \"lambda_mult\": config[\"lambda_mult\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the retriever is functioning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import re\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"AUX-PL-001(A) RISK MANAGEMENT TRAINING REQUIREMENTS FOR THE COAST GUARD AUXILIARY\")\n",
    "\n",
    "\n",
    "# Regular expression pattern to match metadata inside parentheses\n",
    "metadata_pattern = re.compile(r\"metadata=\\{(.*?)\\}\")\n",
    "\n",
    "# Function to extract metadata\n",
    "\n",
    "\n",
    "def extract_metadata(doc_list):\n",
    "    metadata_list = []\n",
    "    for doc in doc_list:\n",
    "        # Convert doc to string if it's not already a string\n",
    "        if not isinstance(doc, str):\n",
    "            doc = str(doc)\n",
    "\n",
    "        matches = metadata_pattern.findall(doc)\n",
    "        for match in matches:\n",
    "            # Convert the matched string to a dictionary\n",
    "            metadata_dict = eval('{' + match + '}')\n",
    "            metadata_list.append(metadata_dict)\n",
    "    return metadata_list\n",
    "\n",
    "\n",
    "# Extracting metadata\n",
    "metadata_list = extract_metadata(retrieved_docs)\n",
    "\n",
    "# Print each metadata dictionary as a Markdown list item\n",
    "\n",
    "\n",
    "def display_selected_metadata_as_markdown(metadata_list):\n",
    "    # Start with an empty string\n",
    "    markdown_string = \"\"\n",
    "\n",
    "    # Iterate over each metadata dictionary\n",
    "    for metadata in metadata_list:\n",
    "        # Extract the /Title and page values\n",
    "        title = metadata.get('/Title', 'No Title')\n",
    "        source = metadata.get('source', 'No Source')\n",
    "        page = metadata.get('page', 'No Page')\n",
    "\n",
    "        # Add them as a list item in the markdown string\n",
    "        markdown_string += \"Title: {}, Source: {}, Page: {}  \\n\".format(\n",
    "            title, source, page)\n",
    "\n",
    "    # Display the markdown string\n",
    "    display(Markdown(markdown_string))\n",
    "\n",
    "\n",
    "# Assuming metadata_list is your list of metadata dictionaries\n",
    "display_selected_metadata_as_markdown(metadata_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b0d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
