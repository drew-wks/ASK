{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bdf56e",
   "metadata": {},
   "source": [
    "# Upsert PDFs to qdrant\n",
    "#### IT's designed to operate in PDF-wise fashion, unlike my previous ones that loaded and chunked an entire PDF in one go. THis one loads and chunks PDFs one at a time to enable for checking the id and enabling some better error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip list # See what's installed and versions\n",
    "# %pip install openai==0.27.8\n",
    "# %pip install langchain==0.0.315\n",
    "# %pip install langchain-community\n",
    "%pip install langchain-qdrant\n",
    "# %pip install qdrant-client==1.6.3\n",
    "# %pip install pympler==1.1.3\n",
    "# %pip install pypdf==5.0.1\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda072",
   "metadata": {},
   "source": [
    "## 0. Imports and Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e257d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-main/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Confirm you're using the correct interpreter\n",
    "#\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fdc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path so you can import library_utils from a subdirectory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf80b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGSMITH CONFIG\n",
    "# These have to be set as environmental variables to be accessed behind the scenes\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = st.secrets[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ASK_main_upsert_notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "# for langchain_openai.OpenAIEmbeddings\n",
    "OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "CONFIG = {\n",
    "    \"splitter_type\": \"CharacterTextSplitter\",\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": len,\n",
    "    \"separators\": [\"}\"],  # [\" \", \",\", \"\\n\"]\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"embedding_dims\": 1536,\n",
    "    \"model\": \"gpt-3.5-turbo-16k\",  # gpt-4, gpt-3.5-turbo-16k\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e82ee0",
   "metadata": {},
   "source": [
    "## 2. Initialize the Qdrant and LC Vectorstore objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c665ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG: qdrant\n",
    "qdrant_collection_name = \"ASK_vectorstore\"\n",
    "# Only required for local instance (actual location is MacHD: private tmp local_qdrant)\n",
    "qdrant_path = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/qdrant\"\n",
    "qdrant_url = st.secrets[\"QDRANT_URL\"]\n",
    "qdrant_api_key = st.secrets[\"QDRANT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a90112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "583113b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_qdrant.qdrant.QdrantVectorStore at 0x168a90f50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "qdrant = QdrantVectorStore(client=client,\n",
    "                           collection_name=qdrant_collection_name,\n",
    "                           # embedding here is LC interface to the embedding model\n",
    "                           embedding=CONFIG[\"embedding\"],\n",
    "                           )\n",
    "\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d35529",
   "metadata": {},
   "source": [
    "## 3. Load PDFs into LangChain Document objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4e852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "def is_pdf_id_in_qdrant(pdf_id: str) -> bool:\n",
    "    '''Helper function checks if pdf_id is already in Qdrant'''\n",
    "\n",
    "    response = client.count(\n",
    "        collection_name=qdrant_collection_name,\n",
    "        count_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"metadata.pdf_id\",\n",
    "                    match=models.MatchText(text=pdf_id),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        exact=True,  # Ensures accurate count\n",
    "    )\n",
    "\n",
    "    return response.count > 0\n",
    "\n",
    "\n",
    "# usage\n",
    "is_pdf_id_in_qdrant(\"df6b2344-b73b-5c11-9f3e-aa2a370b1696\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1384586c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 037_24_CHIEF_DIRECTORS_FINAL_ACTION_ON_NATIONAL_BOARD_RECOMMENDATIONS_AT_NACON_2024_01NOV24.pdf\n",
      "number of pages processed: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import library_utils as lib\n",
    "\n",
    "source_directory = \"./raw_pdfs\"\n",
    "\n",
    "\n",
    "def load_pdf(source_directory, filename):\n",
    "    \"\"\"Loads a PDF and adds enriched metadata.\n",
    "\n",
    "    Args:\n",
    "        source_directory (str): The directory where the PDF is located.\n",
    "        filename (str): The name of the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Langchain page document objects with enriched metadata.\n",
    "    \"\"\"\n",
    "    pdf_path = os.path.join(source_directory, filename)\n",
    "    pages = []\n",
    "\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        docs = loader.load()  # This returns a list of LC page document objects\n",
    "\n",
    "        with open(pdf_path, \"rb\") as pdf_file_obj:\n",
    "            reader = pypdf.PdfReader(pdf_file_obj)\n",
    "            enriched_metadata = {\n",
    "                # \"original_metadata\": reader.metadata,\n",
    "                \"page_count\": len(reader.pages),\n",
    "                \"pdf_id\": lib.compute_pdf_id(pdf_path)\n",
    "            }\n",
    "\n",
    "        # Check if the PDF ID is already in Qdrant\n",
    "        if is_pdf_id_in_qdrant(enriched_metadata[\"pdf_id\"]):\n",
    "            raise ValueError(\n",
    "                f\"PDF with ID {enriched_metadata['pdf_id']} is already in Qdrant.\")\n",
    "\n",
    "        for doc in docs:\n",
    "            doc.metadata.update(enriched_metadata)\n",
    "            pages.append(doc)\n",
    "\n",
    "        print(f\"Processed {filename}\")\n",
    "        print(\"number of pages processed:\", len(pages))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "pages = load_pdf(source_directory,\n",
    "                 \"037_24_CHIEF_DIRECTORS_FINAL_ACTION_ON_NATIONAL_BOARD_RECOMMENDATIONS_AT_NACON_2024_01NOV24.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f977e58",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Example enriched Langchain Page Document object\n",
    "\n",
    "```python\n",
    "page_content='Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus nunc sapien' metadata={'source': './raw_pdfs/lorem_ipsum.pdf', 'page': 1, 'page_count': 13, 'pdf_id': 'df6b2344-b73b-5c11-9f3e-aa2a370b1696'}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea2a89",
   "metadata": {},
   "source": [
    "## 3. Chunk the Pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab05e49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './raw_pdfs/037_24_CHIEF_DIRECTORS_FINAL_ACTION_ON_NATIONAL_BOARD_RECOMMENDATIONS_AT_NACON_2024_01NOV24.pdf', 'page': 0, 'page_count': 3, 'pdf_id': '5e7e959c-02d4-5cc1-9f05-340917525134'}, page_content=\" \\nPage 1 of 3  \\n01 NOV 24 \\nFM:  CHDIRAUX  \\nTO:  ALAUX  \\nALAUX 037/24   Subj:  CHIEF DIRECTOR â€™S FINAL ACTION ON NATIONAL BOARD RECOMMENDATIONS \\nAT NACON 2024 \\n \\n 1.  At the 2024 Auxiliary National Convention (NACON), recently held in Orlando, Florida, three recommendations were placed before the National Board. They are copied below along with the Chief Director's final actions.   \\n  \\na.  Subject: Recommendation to Have All Auxiliary Members Be Also Members of the Auxiliary Association (Originator: Commodore Gus Formato / 29 May 2024)  \\n  \\n(1) Recommendation:  It is recommended that all members who have enrolled from 20 JUL 2022 to date and going forward all new members, also become members of the Auxiliary Association, formerly known as AuxA.   (2) Discussion:   In 2022 a recommendation was passed by the National Board and \\napproved by BSX on 20 JUL 2022, that made provisions for a second 501C3 (sic), to be formed and members of the Auxiliary be removed from AuxA to gain a substantial reduction in insurance rates. However, it was determined that the substantial reduction could be achieved by changing insurance carriers instead of creating a second 501C3 and removing Auxiliary members from AuxA. The second 501C3 was not created and members were not r emoved from AuxA. This recommendation would have all members \\nwho enrolled since 20 JUL 2022 and all new members going forward become members of the Auxiliary Association, formerly known as AuxA.    (3) National Board Action:  Approved.  \\n  (4) Chief Director Final Action:   Concur, approved. This effectively reinstitutes the \\nrequirement for consent to Auxiliary Association membership by all Auxiliarists in order to comply with the District of Columbia Nonprofit Corporations Act (the Auxiliary Association is incorporated in the District of Columbia).  \\n  \\n(a) With issuance of this ALAUX, the continued Auxiliary membership of Auxiliarists who have enrolled since 20 July 2022 constitutes consent to membership in the Auxiliary Association. No additional action on their part is necessary.   \\n\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# chunks at the page break\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CONFIG[\"chunk_size\"],\n",
    "    chunk_overlap=CONFIG[\"chunk_overlap\"],\n",
    "    length_function=CONFIG[\"length_function\"],\n",
    "    separators=CONFIG[\"separators\"]\n",
    ")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "'''\"chunks\" is a list of objects of the class langchain.schema.document.Document'''\n",
    "print(\"number of chunks:\", len(chunks))\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1d5c5",
   "metadata": {},
   "source": [
    "## 4. Add chunks to Qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d3a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_qdrant.qdrant.QdrantVectorStore at 0x168a207d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .from_documents  creates the Qdrant vectorstore object with the documents/chunks, embeddings, and metadata and automatically configures the collection.  It is a Langchain class method used to initialize a new Qdrant instance with a collection of documents all at once.\n",
    "\n",
    "qdrant.from_documents(\n",
    "    chunks,\n",
    "    embedding=CONFIG[\"embedding\"],  \n",
    "    collection_name=qdrant_collection_name,  \n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key, \n",
    "    # keep this to false so you don[t overwrite your collection\n",
    "    force_recreate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9d64f",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"><b>CONGRATULATIONS: You're done</b></span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
