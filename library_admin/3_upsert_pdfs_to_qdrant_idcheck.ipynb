{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bdf56e",
   "metadata": {},
   "source": [
    "# Upsert PDFs to qdrant\n",
    "#### This is an entire workflow from PDF to RAG.\n",
    "#### It uses a now deprecated version of the langchain qdrant vectorstore object which does not allow for adjustment to metadata during the upsert process. As a result, it relied on a process of adding metadata to the pdfs prior to chunking them. This was less than ideal as the pdf standard adds a '/' to each field which renders them inaccessible as filter keys in Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e257d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-main/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Confirm you're using the correct interpreter\n",
    "#\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fdc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path so you can import library_utils from a subdirectory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda072",
   "metadata": {},
   "source": [
    "## 0. Installs and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip list # See what's installed and versions\n",
    "# %pip install openai==0.27.8\n",
    "# %pip install langchain==0.0.315\n",
    "# %pip install langchain-community\n",
    "# %pip install --upgrade docarray\n",
    "# %pip install python-doten\n",
    "# %pip install --upgrade wandb\n",
    "# %pip install qdrant-client==1.6.3\n",
    "# %pip install pympler==1.1.3\n",
    "# %pip install pypdf==5.0.1\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ee90e",
   "metadata": {},
   "source": [
    "### Langsmith\n",
    "accessible [here](https://smith.langchain.com/o/3941ecea-6957-508c-9f4f-08ed62dc7d61/projects/p/0aea481f-080e-45eb-bae1-2ae8ee246bd9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf80b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGSMITH CONFIG\n",
    "#\n",
    "# These have to be set as environmental variables to be accessed behind the scenes\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "env_path = find_dotenv()\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = st.secrets[\"LANGCHAIN_TRACING_V2\"]\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = st.secrets[\"LANGCHAIN_PROJECT\"]\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = st.secrets[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ASK_main_upsert_notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "# for langchain_openai.OpenAIEmbeddings\n",
    "OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5540a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONFIG = {\n",
    "    \"splitter_type\": \"CharacterTextSplitter\",\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": len,\n",
    "    \"separators\": [\"}\"],  # [\" \", \",\", \"\\n\"]\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"embedding_dims\": 1536,\n",
    "    \"model\": \"gpt-3.5-turbo-16k\",  # gpt-4, gpt-3.5-turbo-16k\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Langchain debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c665ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG: qdrant\n",
    "qdrant_collection_name = \"ASK_vectorstore\"\n",
    "# Only required for local instance (actual location is MacHD: private tmp local_qdrant)\n",
    "qdrant_path = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/qdrant\"\n",
    "# qdrant_path = \"/tmp/local_qdrant\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./raw_pdfs\"\n",
    "filename = \"lorem_ipsum.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea41ef",
   "metadata": {},
   "source": [
    "THESE WILl END UP BEING HELPER FUNCTIONS IN LIBRARY UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada38f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='ask_pdf_pages'), CollectionDescription(name='ASK_vectorstore'), CollectionDescription(name='ask_pdf_docs')]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import exceptions as qdrant_exceptions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4e852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "def is_pdf_id_in_qdrant(pdf_id: str) -> bool:\n",
    "    '''Helper function checks if pdf_id is already in Qdrant\n",
    "    \n",
    "    usage\n",
    "    is_pdf_id_in_qdrant(\"df6b2344-b73b-5c11-9f3e-aa2a370b1696\")\n",
    "    '''\n",
    "    client = QdrantClient(\n",
    "    url=st.secrets[\"QDRANT_URL\"], api_key=st.secrets[\"QDRANT_API_KEY\"])\n",
    "    \n",
    "    response = client.count(\n",
    "        collection_name=qdrant_collection_name,\n",
    "        count_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"metadata.pdf_id\",\n",
    "                    match=models.MatchText(text=pdf_id),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        exact=True,  # Ensures accurate count\n",
    "    )\n",
    "    return response.count > 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e82ee0",
   "metadata": {},
   "source": [
    "## 2. Load PDFs into LangChain Document objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import library_utils as lib\n",
    "\n",
    "\n",
    "def load_pdf(source_directory, filename):\n",
    "    \"\"\"Loads a PDF and adds enriched metadata.\n",
    "\n",
    "    Args:\n",
    "        source_directory (str): The directory where the PDF is located.\n",
    "        filename (str): The name of the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Langchain page document objects with enriched metadata.\n",
    "    \"\"\"\n",
    "    pdf_path = os.path.join(source_directory, filename)\n",
    "    pages = []\n",
    "\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        docs = loader.load()  # This returns a list of LC page document objects\n",
    "\n",
    "        with open(pdf_path, \"rb\") as pdf_file_obj:\n",
    "            reader = pypdf.PdfReader(pdf_file_obj)\n",
    "            enriched_metadata = {\n",
    "                # \"original_metadata\": reader.metadata,\n",
    "                \"page_count\": len(reader.pages),\n",
    "                \"pdf_id\": lib.compute_pdf_id(pdf_path)\n",
    "            }\n",
    "\n",
    "        # Check if the PDF ID is already in Qdrant\n",
    "        if is_pdf_id_in_qdrant(enriched_metadata[\"pdf_id\"]):\n",
    "            raise ValueError(f\"PDF with ID {enriched_metadata['pdf_id']} is already in Qdrant.\")\n",
    "\n",
    "        for doc in docs:\n",
    "            doc.metadata.update(enriched_metadata)\n",
    "            pages.append(doc)\n",
    "\n",
    "        print(f\"Processed {filename}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a964e6c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9db98f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed lorem_ipsum.pdf\n"
     ]
    }
   ],
   "source": [
    "pages = load_pdf(source_directory, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f977e58",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Example enriched Langchain Page Document object\n",
    "\n",
    "```python\n",
    "page_content='Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus nunc sapien' metadata={'source': './raw_pdfs/lorem_ipsum.pdf', 'page': 1, 'page_count': 13, 'pdf_id': 'df6b2344-b73b-5c11-9f3e-aa2a370b1696'}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462f846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='peeesqueebsedooacusbeoospeeesquedaelectus. In hac habitasse platea dictumst. Phasellus mauris enim, posuere eget    luctus ac, iaculis et quam. Vivamus et nibh diam, elementum egestas tellus. Aenean    vulputate malesuada est. Sed posuere porta diam a sodales. Proin eu sem non velit    facilisis venenatis sed a turpis.    Pellentesque sed risus a ante vulputate lobortis sit amet eu nisl. Suspendisse ut eros mi, a rhoncus lacus. Curabitur fermentum vehicula tellus, a ornare mi    condimentum vel. Integer molestie volutpat viverra. Integer posuere euismod    venenatis. Proin ac mauris sed nulla pharetra porttitor. Duis vel dui in risus    sodales auctor sit amet non enim. Maecenas mollis lacus at ligula faucibus    sodales. Cras vel neque arcu. Sed tincidunt tortor pretium nisi interdum quis    dictum arcu laoreet. Morbi pretium ultrices feugiat. Maecenas convallis augue nec    felis malesuada malesuada scelerisque mauris placerat. Sed at magna enim, at    fringilla dolor. Quisque ut mattis dui. Praesent consectetur ante viverra nisi    blandit pharetra. Quisque metus elit, dignissim vitae fermentum sit amet,    fringilla imperdiet odio. Cras eget purus eget tellus feugiat luctus a ac purus.    Cras vitae nisl vel augue rhoncus porttitor sit amet quis lorem. Donec interdum    pellentesque adipiscing. Phasellus neque libero, aliquam in mattis vitae,    consectetur adipiscing nibh.    Donec nec nulla urna, ac sagittis lectus. Suspendisse non elit sed mi auctor facilisis vitae et lectus. Fusce ac vulputate mauris. Morbi condimentum ultrices    metus, et accumsan purus malesuada at. Maecenas lobortis ante sed massa dictum    vitae venenatis elit commodo. Proin tellus eros, adipiscing sed dignissim vitae,    tempor eget ante. Aenean id tellus nec magna cursus pharetra vitae vel enim. Morbi    vestibulum pharetra est in vulputate. Aliquam vitae metus arcu, id aliquet nulla.    Phasellus ligula est, hendrerit nec iaculis ut, volutpat vel eros. Suspendisse    vitae urna turpis, placerat adipiscing diam. Phasellus feugiat vestibulum neque eu    dapibus. Nulla facilisi. Duis tortor felis, euismod sit amet aliquet in, volutpat    nec turpis. Mauris rhoncus ipsum ut purus eleifend ut lobortis lectus dapibus.    Quisque non erat lorem. Vivamus posuere imperdiet iaculis. Ut ligula lacus,    eleifend at tempor id, auctor eu leo.    Donec mi enim, laoreet pulvinar mollis eu, malesuada viverra nunc. In vitae metus vitae neque tempor dapibus. Maecenas tincidunt purus a felis aliquam placerat.    Nulla facilisi. Suspendisse placerat pharetra mattis. Integer tempor malesuada    justo at tempus. Maecenas vehicula lorem a sapien bibendum vel iaculis risus    feugiat. Pellentesque diam erat, dapibus et pellentesque quis, molestie ut massa.    Vivamus iaculis interdum massa id bibendum. Quisque ut mauris dui, sit amet varius    elit. Vestibulum elit lorem, rutrum non consectetur ut, laoreet nec nunc. Donec    nec mauris ante. Curabitur ut est sed odio pharetra laoreet. Lorem ipsum dolor sit    amet, consectetur adipiscing elit. Curabitur purus risus, laoreet sed porta id,    sagittis vel ipsum. Maecenas nibh diam, cursus et varius sit amet, fringilla sed    magna. Nullam id neque eu leo faucibus mollis. Duis nec adipiscing mauris.    Suspendisse sollicitudin, enim eu pulvinar commodo, erat augue ultrices mi, a    tristique magna sem non libero.   \n",
      "' metadata={'source': './raw_pdfs/lorem_ipsum.pdf', 'page': 1, 'page_count': 13, 'pdf_id': 'df6b2344-b73b-5c11-9f3e-aa2a370b1696'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea2a89",
   "metadata": {},
   "source": [
    "## 3. Chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a9e61",
   "metadata": {},
   "source": [
    "## <span style=\"color:YELLOW\"><b>HAVENT DONE ANYTHING WITH THIS YET</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_pdfs(pdfs_source_dir):\n",
    "    file_list = []\n",
    "    pages = []\n",
    "    total_size = 0\n",
    "\n",
    "    # Check if the path is a directory or a file\n",
    "    if os.path.isdir(pdfs_source_dir):\n",
    "        print(\"Loading PDFs from directory...\")\n",
    "        for foldername, subfolders, filenames in os.walk(pdfs_source_dir):\n",
    "            for file in filenames:\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    process_pdf(os.path.join(foldername, file),\n",
    "                                file_list, pages, total_size)\n",
    "    elif os.path.isfile(pdfs_source_dir) and pdfs_source_dir.lower().endswith('.pdf'):\n",
    "        print(\"Loading a single PDF file...\")\n",
    "        process_pdf(pdfs_source_dir, file_list, pages, total_size)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Error: The path '{pdfs_source_dir}' is not a valid directory or PDF file!\")\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path, file_list, pages, total_size):\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        file_processed = False  # Flag to track if the file has been processed\n",
    "\n",
    "        for doc in documents:\n",
    "            with open(doc.metadata[\"source\"], \"rb\") as pdf_file_obj:\n",
    "                reader = pypdf.PdfReader(pdf_file_obj)\n",
    "                pdf_metadata = reader.metadata\n",
    "                doc.metadata.update(\n",
    "                    {key: pdf_metadata[key] for key in pdf_metadata.keys()})\n",
    "\n",
    "            pages.append(doc)\n",
    "            if not file_processed:\n",
    "                file_list.append(pdf_path.split('/')[-1])\n",
    "                total_size += os.path.getsize(pdf_path)\n",
    "                file_processed = True  # Set flag to True after processing the file\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "\n",
    "    if file_processed:\n",
    "        print(f\"Processed {pdf_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "pages = extract_metadata_from_pdfs(source_directory)\n",
    "if pages:\n",
    "    last_page = pages[-1]\n",
    "else:\n",
    "    print(\"No pages were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# chunks at the page break\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CONFIG[\"chunk_size\"],\n",
    "    chunk_overlap=CONFIG[\"chunk_overlap\"],\n",
    "    length_function=CONFIG[\"length_function\"],\n",
    "    separators=CONFIG[\"separators\"]\n",
    ")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "# concat.pages_to_page(pages) #concatenates all the pages of the pdf into one\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "'''\"chunks\" is a list of objects of the class langchain.schema.document.Document'''\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_document_load_summary(source_directory):\n",
    "    from pympler import asizeof\n",
    "    import tiktoken\n",
    "\n",
    "    encoding = tiktoken.encoding_for_model(CONFIG[\"model\"])\n",
    "    vectorstore_tokens = encoding.encode(str(chunks))\n",
    "    num_vectorestore_tokens = len(vectorstore_tokens)\n",
    "    num_chunks = len(chunks)\n",
    "    # Qudrant's formula is memory_size in bytes = number_of_vectors * vector_dimension * 4 bytes * 1.5\n",
    "    memory_size = num_chunks * CONFIG[\"embedding_dims\"] * 4 * 1.5\n",
    "\n",
    "    print(f\"\"\"\n",
    "        Source folder: {source_directory}\n",
    "        Pages processed: {len(pages)}\n",
    "        Text splitter: {CONFIG[\"splitter_type\"]}\n",
    "        Chunk size: {CONFIG[\"chunk_size\"]} characters\n",
    "        Chunk overlap: {CONFIG[\"chunk_overlap\"]} characters\n",
    "        Chunks (vectors) created: {num_chunks} \n",
    "        Dictionary size: {asizeof.asizeof(pages) / (1024 * 1024):.2f} MB\n",
    "        Vectorstore tokens: {num_vectorestore_tokens}\n",
    "        Estimated memory size (Qdrant): {memory_size / (1024 * 1024):.2f} MB\n",
    "    \"\"\")\n",
    "\n",
    "    ''' TODO These variables are now in a function so not accessible.    \n",
    "        Document(s)loaded: {len(file_list)}\n",
    "        Load size: {total_size / (1024 * 1024):.2f} MB\n",
    "        '''\n",
    "\n",
    "\n",
    "print_document_load_summary(source_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1d5c5",
   "metadata": {},
   "source": [
    "## 4. Add chunks to Qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "qdrant = QdrantVectorStore(client=client,\n",
    "                collection_name=qdrant_collection_name,\n",
    "                # embedding here is LC interface to the embedding model\n",
    "                embedding=CONFIG[\"embedding\"],\n",
    "                )\n",
    "\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d3a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .from_documents  creates the Qdrant vectorstore object with the documents/chunks, embeddings, and metadata and automatically configures the collection.  It is a Langchain class method used to initialize a new Qdrant instance with a collection of documents all at once.\n",
    "\n",
    "qdrant.from_documents(\n",
    "    chunks,\n",
    "    embedding=CONFIG[\"embedding\"],  # yes this is required here too\n",
    "    # path=qdrant_path,  # Only required for local instance\n",
    "    collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "    url=st.secrets[\"QDRANT_URL\"],\n",
    "    api_key=st.secrets[\"QDRANT_API_KEY\"],  # Only required for Qdrant Cloud\n",
    "    # keep this to falsse so you don[t overwrite your collection\n",
    "    force_recreate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9d64f",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"><b>CONGRATULATIONS: You're done</b></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937261bc",
   "metadata": {},
   "source": [
    "## OPTIONAL: Create NEW vector store and add documents into it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8c8db",
   "metadata": {},
   "source": [
    "#### Combo Create + Add Docs\n",
    "\n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing Qdrant collection</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "\n",
    "def create_localdb_and_add_chunks():\n",
    "    \"\"\"Use only to create the vectore db and load docs the first time. \n",
    "\n",
    "    .from_documents  creates the Qdrant vectorstore object with the documents/chunks, embeddings, and metadata and automatically configures the collection.  It is a Langchain class method used to initialize a new Qdrant instance with a collection of documents all at once.\n",
    "\n",
    "    It overcomes limitations in Langchain by releaseing the vecDB afterwards\"\"\"\n",
    "\n",
    "    client = QdrantClient()\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=qdrant_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=CONFIG[\"embedding\"],\n",
    "                    )\n",
    "    qdrant.from_documents(\n",
    "        chunks,\n",
    "        embedding=CONFIG[\"embedding\"],  # yes this is required here too\n",
    "        path=qdrant_path,  # Only required for local instance\n",
    "        collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "        # url=os.environ.get(\"QDRANT_URL\"),\n",
    "        # Only required for Qdrant Cloud\n",
    "        # api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    "        force_recreate=False,  # don't use if db doesn't already exist\n",
    "    )\n",
    "    # print(client.get_collections())\n",
    "    # print(\n",
    "    # f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")\n",
    "\n",
    "\n",
    "check_me = create_localdb_and_add_chunks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed726a9b",
   "metadata": {},
   "source": [
    "#### Create new Qdrant DB / Collection.\n",
    "\n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing Qdrant collection</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may not work\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "client = QdrantClient(\n",
    "    path=qdrant_path\n",
    ")  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=new_collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=CONFIG[\"embedding_dims\"], distance=models.Distance.COSINE)\n",
    ")\n",
    "# You may need to delete the lock file to access this afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24657b",
   "metadata": {},
   "source": [
    "#### Add Documents with Timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def add_chunks_to_existingdb_with_delay(batch_size, delay):\n",
    "    \"\"\"\n",
    "    Use only to create the vectore db and load docs the first time. (7min)\n",
    "    This version loads the chunks into the vector store with a delay.\n",
    "\n",
    "    Unlike .from_documents, which is a class method of Qdrant, \n",
    "    this uses  .add_documents which is an instance method of DocArrayInMemorySearch.\n",
    "    This means you have to set up th Qdrant instance first before using it. \n",
    "    By separating the two we can insert a timer delay. It releases the vecDB afterwards.\n",
    "\n",
    "    USAGE: Aim for ~800K tokens and then have the timer delay until 60 sec is reached\n",
    "    \"\"\"\n",
    "\n",
    "    from qdrant_client import QdrantClient\n",
    "    from langchain.vectorstores import Qdrant\n",
    "\n",
    "    client = QdrantClient(\n",
    "        path=qdrant_path\n",
    "    )  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=new_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=CONFIG[\"embedding\"],\n",
    "                    )\n",
    "\n",
    "    # generate indices starting from 0. increment by batch_size until len(chunks)\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]  # Create a batch of chunks\n",
    "        qdrant.add_documents(documents=batch)  # Add the batch of chunks\n",
    "        # pause time probably don't need to be changed since tokens usually hit limit by 18 sec.\n",
    "        time.sleep(delay)\n",
    "\n",
    "    del qdrant\n",
    "    client.close()    # Release the database from this process\n",
    "    del client\n",
    "\n",
    "\n",
    "add_chunks_to_existingdb_with_delay(1700, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f26af",
   "metadata": {},
   "source": [
    "## OPTIONAL: Close Client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
