{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bda072",
   "metadata": {},
   "source": [
    "## 0. Installs and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip list # See what's installed and versions\n",
    "\n",
    "\n",
    "# %pip install --upgrade langchain\n",
    "# %pip install --upgrade docarray\n",
    "# %pip install python-doten\n",
    "# %pip install --upgrade wandb\n",
    "# %pip install qdrant-client # applies to all qdrant implementations\n",
    "# %pip install pypdf\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730057d3",
   "metadata": {},
   "source": [
    "## 1. Set the model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "config = {\n",
    "    \"splitter_type\": \"CharacterTextSplitter\",\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": len,\n",
    "    \"separators\": [\"}\"],  # [\" \", \",\", \"\\n\"]\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"embedding_dims\": 1536,\n",
    "    \"search_type\": \"mmr\",\n",
    "    'fetch_k': 20,   # number of documents to pass to the search alg (eg., mmr)\n",
    "    \"k\": 5,  # number of document from fetch to pass to the LLM for inference\n",
    "    'lambda_mult': .7,    # 0= max diversity, 1 is max relevance. default is 0.5\n",
    "    \"score_threshold\": 0.5,  # for similarity score\n",
    "    \"model\": \"gpt-3.5-turbo-16k\",  # gpt-4, gpt-3.5-turbo-16k\n",
    "    \"temperature\": 0.7,\n",
    "    \"chain_type\": \"stuff\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Langchain debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c665ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_collection_name = \"ASK_vectorstore\"\n",
    "# Only required for local instance (actual location is MacHD: private tmp local_qdrant)\n",
    "qdrant_path = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/qdrant\"\n",
    "# qdrant_path = \"/tmp/local_qdrant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea2a89",
   "metadata": {},
   "source": [
    "## 3. Chunk 'n' Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pypdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "def extract_metadata_from_pdfs(path_to_ingest_files):\n",
    "    file_list = []\n",
    "    pages = []\n",
    "    total_size = 0\n",
    "\n",
    "    # Check if the path is a directory or a file\n",
    "    if os.path.isdir(path_to_ingest_files):\n",
    "        print(\"Loading PDFs from directory...\")\n",
    "        for foldername, subfolders, filenames in os.walk(path_to_ingest_files):\n",
    "            for file in filenames:\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    process_pdf(os.path.join(foldername, file),\n",
    "                                file_list, pages, total_size)\n",
    "    elif os.path.isfile(path_to_ingest_files) and path_to_ingest_files.lower().endswith('.pdf'):\n",
    "        print(\"Loading a single PDF file...\")\n",
    "        process_pdf(path_to_ingest_files, file_list, pages, total_size)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Error: The path '{path_to_ingest_files}' is not a valid directory or PDF file!\")\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path, file_list, pages, total_size):\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        file_processed = False  # Flag to track if the file has been processed\n",
    "\n",
    "        for doc in documents:\n",
    "            with open(doc.metadata[\"source\"], \"rb\") as pdf_file_obj:\n",
    "                reader = pypdf.PdfReader(pdf_file_obj)\n",
    "                pdf_metadata = reader.metadata\n",
    "                doc.metadata.update(\n",
    "                    {key: pdf_metadata[key] for key in pdf_metadata.keys()})\n",
    "\n",
    "            pages.append(doc)\n",
    "            if not file_processed:\n",
    "                file_list.append(pdf_path.split('/')[-1])\n",
    "                total_size += os.path.getsize(pdf_path)\n",
    "                file_processed = True  # Set flag to True after processing the file\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "\n",
    "    if file_processed:\n",
    "        print(f\"Processed {pdf_path.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "path_to_ingest_files = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/original_library_documents/CG_Auxiliary-specific\"\n",
    "pages = extract_metadata_from_pdfs(path_to_ingest_files)\n",
    "if pages:\n",
    "    last_page = pages[-1]\n",
    "else:\n",
    "    print(\"No pages were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# chunks at the page break\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config[\"chunk_size\"],\n",
    "    chunk_overlap=config[\"chunk_overlap\"],\n",
    "    length_function=config[\"length_function\"],\n",
    "    separators=config[\"separators\"]\n",
    ")\n",
    "\n",
    "\n",
    "'''usage'''\n",
    "# concat.pages_to_page(pages) #concatenates all the pages of the pdf into one\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "'''\"chunks\" is a list of objects of the class langchain.schema.document.Document'''\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_document_load_summary():\n",
    "    from pympler import asizeof\n",
    "    import tiktoken\n",
    "\n",
    "    encoding = tiktoken.encoding_for_model(config[\"model\"])\n",
    "    vectorstore_tokens = encoding.encode(str(chunks))\n",
    "    num_vectorestore_tokens = len(vectorstore_tokens)\n",
    "    num_chunks = len(chunks)\n",
    "    # Qudrant's formula is memory_size in bytes = number_of_vectors * vector_dimension * 4 bytes * 1.5\n",
    "    memory_size = num_chunks * config[\"embedding_dims\"] * 4 * 1.5\n",
    "\n",
    "    print(f\"\"\"\n",
    "        Target folder: {path_to_ingest_files}\n",
    "        Pages processed: {len(pages)}\n",
    "        Text splitter: {config[\"splitter_type\"]}\n",
    "        Chunk size: {config[\"chunk_size\"]} characters\n",
    "        Chunk overlap: {config[\"chunk_overlap\"]} characters\n",
    "        Chunks (vectors) created: {num_chunks} \n",
    "        Dictionary size: {asizeof.asizeof(pages) / (1024 * 1024):.2f} MB\n",
    "        Vectorstore tokens: {num_vectorestore_tokens}\n",
    "        Estimated memory size (Qdrant): {memory_size / (1024 * 1024):.2f} MB\n",
    "    \"\"\")\n",
    "\n",
    "    ''' TODO These variables are now in a function so not accessible.    \n",
    "        Document(s)loaded: {len(file_list)}\n",
    "        Load size: {total_size / (1024 * 1024):.2f} MB\n",
    "        '''\n",
    "\n",
    "\n",
    "print_document_load_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937261bc",
   "metadata": {},
   "source": [
    "## 4. OPTIONAL: Create NEW vector store and add documents into it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combo Create + Add Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "qdrant = Qdrant(client=client,\n",
    "                collection_name=qdrant_collection_name,\n",
    "                # embedding here is LC interface to the embedding model\n",
    "                embeddings=config[\"embedding\"],\n",
    "                )\n",
    "\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant.from_documents(\n",
    "    chunks,\n",
    "    embedding=config[\"embedding\"],  # yes this is required here too\n",
    "    # path=qdrant_path,  # Only required for local instance\n",
    "    collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "    url=os.environ.get(\"QDRANT_URL\"),\n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),  # Only required for Qdrant Cloud\n",
    "    force_recreate=False,  # don't use if db doesn't already exist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "\n",
    "def create_localdb_and_add_docs():\n",
    "    \"\"\"Use only to create the vectore db and load docs the first time. \n",
    "    It overcomes limitations in Langchain by releaseing the vecDB afterwards\"\"\"\n",
    "\n",
    "    client = QdrantClient()\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=qdrant_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "    qdrant.from_documents(\n",
    "        chunks,\n",
    "        embedding=config[\"embedding\"],  # yes this is required here too\n",
    "        path=qdrant_path,  # Only required for local instance\n",
    "        collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "        # url=os.environ.get(\"QDRANT_URL\"),\n",
    "        # Only required for Qdrant Cloud\n",
    "        # api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    "        force_recreate=False,  # don't use if db doesn't already exist\n",
    "    )\n",
    "    # print(client.get_collections())\n",
    "    # print(\n",
    "    # f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")\n",
    "\n",
    "\n",
    "check_me = create_localdb_and_add_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new Qdrant DB / Collection. \n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing one</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may not work\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "client = QdrantClient(\n",
    "    path=qdrant_path\n",
    ")  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=qdrant_collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "# You may need to delete the lock file to access this afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Documents with Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def add_docs_to_existingdb_with_delay(batch_size, delay):\n",
    "    \"\"\"Use only to create the vectore db and load docs the first time. (7min)\n",
    "    It overcomes limitations in Langchain by releasing the vecDB afterwards.\n",
    "    This version loads the chunks into the vector store with a delay\"\"\"\n",
    "\n",
    "    '''Uses the DocArrayInMemorySearch.add_documents\n",
    "    object method. Aim for ~800K tokens and then have \n",
    "    the timer delay until 60 sec is reached'''\n",
    "\n",
    "    from qdrant_client import QdrantClient\n",
    "    from qdrant_client.http import models\n",
    "    from langchain.vectorstores import Qdrant\n",
    "\n",
    "    client = QdrantClient(\n",
    "        path=qdrant_path\n",
    "    )  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=qdrant_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "\n",
    "    # generate indices starting from 0. increment by batch_size until len(chunks)\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]  # Create a batch of chunks\n",
    "        qdrant.add_documents(documents=batch)  # Add the batch of chunks\n",
    "        # pause time probably don't need to be changed since tokens usually hit limit by 18 sec.\n",
    "        time.sleep(delay)\n",
    "\n",
    "    del qdrant\n",
    "    client.close()    # Release the database from this process\n",
    "    del client\n",
    "\n",
    "\n",
    "add_docs_to_existingdb_with_delay(1700, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1c0a3",
   "metadata": {},
   "source": [
    "## 4. Connect to Vector Store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cdedd8",
   "metadata": {},
   "source": [
    "#### Option A: Init Qdrant Cloud service entrypoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae5b082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='ASK_vectorstore')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "\n",
    "if 'client' not in globals():\n",
    "    client = QdrantClient(url=os.environ.get(\"QDRANT_URL\"),\n",
    "                          api_key=os.environ.get(\"QDRANT_API_KEY\"))\n",
    "else:\n",
    "    print(f\"Client already exists at {client}\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d6a9e",
   "metadata": {},
   "source": [
    "#### Option B: init Qdrant Local service entrypoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "import psutil\n",
    "\n",
    "if 'client' not in globals():\n",
    "    # Only required for local instance``\n",
    "    client = QdrantClient(path=qdrant_path)\n",
    "else:\n",
    "    print(f\"Client already exists at {client}\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b37d60",
   "metadata": {},
   "source": [
    "### Confirm client is initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5319661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client is running via a URL.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.local.qdrant_local import QdrantLocal\n",
    "from qdrant_client.qdrant_remote import QdrantRemote\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check if the client is running locally or via a URL\n",
    "    if isinstance(client._client, QdrantLocal):\n",
    "        print(\"The client is running locally.\")\n",
    "    elif isinstance(client._client, QdrantRemote):\n",
    "        print(\"The client is running via a URL.\")\n",
    "    else:\n",
    "        # This else block handles cases where client._client is neither QdrantLocal nor QdrantRemote\n",
    "        print(\"Unable to determine the running mode of the Qdrant client.\")\n",
    "except Exception as e:\n",
    "    # This block catches any other exceptions that might occur\n",
    "    print(\"Unable to determine the running mode of the Qdrant client. Error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77b836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "\n",
    "qdrant = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=qdrant_collection_name,\n",
    "    # embedding here is a LC interface to the embedding model,\n",
    "    embeddings=config[\"embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f01bb",
   "metadata": {},
   "source": [
    "## 5. Initialize a Document Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c065ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a VectorStoreRetriever called retriever from the LC qdrant vector store object\n",
    "\n",
    "# Option 1 using MMR search\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': config[\"k\"], \"fetch_k\": config[\"fetch_k\"],\n",
    "                   \"lambda_mult\": config[\"lambda_mult\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the retriever is functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Title: Memo-Standard, Source: /Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/original library documents/BSX_Policy_Letters/new_adds/AUX-PL-001(A)_BSX_Policy_Letter_19-01_RISK_MANAGEMENT_TRAINING_FOR_THE_COAST_GUARD_AUXILIARY.pdf, Page: 3  \n",
       "Title: No Title, Source: References/Gold Side/Flotilla_Procedures_Guide_FINAL_ESIGNED_23MAR23.pdf, Page: 0  \n",
       "Title: No Title, Source: For_injestion/2023 Surface Operations_Workshop Rev1.8.pptx.pdf, Page: 29  \n",
       "Title: No Title, Source: For_injestion/2023 Telecomms_TCO_Workshop Rev 1.4.pptx.pdf, Page: 8  \n",
       "Title: No Title, Source: References/Auxiliary Manual CIM_16790_1G.pdf, Page: 363  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "import re\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"AUX-PL-001(A) RISK MANAGEMENT TRAINING REQUIREMENTS FOR THE COAST GUARD AUXILIARY\")\n",
    "\n",
    "\n",
    "# Regular expression pattern to match metadata inside parentheses\n",
    "metadata_pattern = re.compile(r\"metadata=\\{(.*?)\\}\")\n",
    "\n",
    "# Function to extract metadata\n",
    "\n",
    "\n",
    "def extract_metadata(doc_list):\n",
    "    metadata_list = []\n",
    "    for doc in doc_list:\n",
    "        # Convert doc to string if it's not already a string\n",
    "        if not isinstance(doc, str):\n",
    "            doc = str(doc)\n",
    "\n",
    "        matches = metadata_pattern.findall(doc)\n",
    "        for match in matches:\n",
    "            # Convert the matched string to a dictionary\n",
    "            metadata_dict = eval('{' + match + '}')\n",
    "            metadata_list.append(metadata_dict)\n",
    "    return metadata_list\n",
    "\n",
    "\n",
    "# Extracting metadata\n",
    "metadata_list = extract_metadata(retrieved_docs)\n",
    "\n",
    "# Print each metadata dictionary as a Markdown list item\n",
    "\n",
    "\n",
    "def display_selected_metadata_as_markdown(metadata_list):\n",
    "    # Start with an empty string\n",
    "    markdown_string = \"\"\n",
    "\n",
    "    # Iterate over each metadata dictionary\n",
    "    for metadata in metadata_list:\n",
    "        # Extract the /Title and page values\n",
    "        title = metadata.get('/Title', 'No Title')\n",
    "        source = metadata.get('source', 'No Source')\n",
    "        page = metadata.get('page', 'No Page')\n",
    "\n",
    "        # Add them as a list item in the markdown string\n",
    "        markdown_string += \"Title: {}, Source: {}, Page: {}  \\n\".format(\n",
    "            title, source, page)\n",
    "\n",
    "    # Display the markdown string\n",
    "    display(Markdown(markdown_string))\n",
    "\n",
    "\n",
    "# Assuming metadata_list is your list of metadata dictionaries\n",
    "display_selected_metadata_as_markdown(metadata_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12111c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
