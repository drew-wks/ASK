{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  This is the process for grabbing the pdfs and extracting metadat to a library catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It includes adding the metadata we are going to use. The custom metadata list is defined in this code block at the bottom. Custom fields can be defined in the custom_fields list. The functions take the list as an argument and  checks for the additional custom metadata fields and includes them in the xlsx if they are present in the PDF files.\n",
    "##### THis identifies potential duplicate PDF files, you can compute a hash (e.g., SHA-256) for each file and compare these values. Files with the same hash value are very likely to be duplicates.  \n",
    "##### With the check_pdf_issues function in place, before attempting to get metadata from a PDF, the script will first check if the PDF has issues like being encrypted or corrupt. If it's encrypted, it will attempt to decrypt using the provided password (in this case, an empty string). If it's corrupt or if there's any other issue, it will log the problem and skip the file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-4.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Using cached pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bs4 in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (from requests) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tabulate in /Users/drew_wilkins/Drews_Files/Drew/Python/ASK/.venv-311/lib/python3.11/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade pip\n",
    "%pip install -r requirements.txt\n",
    "# %pip install ipython\n",
    "%pip install pypdf\n",
    "\n",
    "%pip install bs4\n",
    "%pip install requests\n",
    "#%pip install openpyxl\n",
    "%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, date, timedelta\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabulate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tabulate\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime, date, timedelta\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This litle code block is used anytime you want to import a local module from within a Jupyter Notebook. This is required becuase Jupyter treats each cell as a module.'''\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Navigate up one level from the current notebook's directory to reach the root directory\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 08:29:15.988 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/holding back until testing is over/\"\n",
    "\n",
    "zulu_format = '%Y-%m-%dT%H:%MZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create metadata dictionary\n",
    "# Check if the path exists\n",
    "def check_dir_exists(source_directory):\n",
    "    if not os.path.exists(source_directory):\n",
    "        print(f\"Error: The path '{source_directory}' does not exist!\")\n",
    "        raise ValueError(f\"The path '{source_directory}' does not exist!\")\n",
    "\n",
    "\n",
    "def compute_pdf_hash(pdf_path):\n",
    "    '''generate a unique hash for the PDF file'''\n",
    "    doc_id = hashlib.md5()\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        for block in iter(lambda: f.read(4096), b\"\"):\n",
    "            doc_id.update(block)\n",
    "    return doc_id.hexdigest()\n",
    "\n",
    "\n",
    "def check_pdf_for_issues(pdf_path):\n",
    "    try:\n",
    "        pdf = PdfReader(pdf_path)\n",
    "        if pdf.is_encrypted:\n",
    "            print(f\"Encryption detected for {pdf_path}\")\n",
    "            pdf.decrypt(\"\")\n",
    "            print(f\"All pages accessed: {len(pdf.pages)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Issue with {pdf_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def remove_multiple_extensions(file_name):\n",
    "    while os.path.splitext(file_name)[1]:\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "    return file_name\n",
    "\n",
    "\n",
    "def get_pdf_metadata(pdf_path):\n",
    "    '''Extract all metadata fields present in the PDF file \n",
    "    along with page count and the hash into a dictionary.'''\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PdfReader(f)\n",
    "        metadata = reader.metadata\n",
    "        file_name = remove_multiple_extensions(os.path.basename(pdf_path))\n",
    "\n",
    "        CreationDate = metadata.get('/CreationDate', '')[2:16]\n",
    "        creation_date = datetime.strptime(\n",
    "            CreationDate, '%Y%m%d%H%M%S') if CreationDate else datetime.utcnow()\n",
    "        expiration_date = creation_date + timedelta(days=365.25 * 10)\n",
    "        creation_date = creation_date.strftime(zulu_format)\n",
    "        return {\n",
    "            'title': metadata.get('/Title', file_name.replace('_', ' ')),\n",
    "            'leadership_scope': \"1_National\",\n",
    "            'page_count': len(reader.pages),\n",
    "            'creation_date': creation_date,\n",
    "            'effective_date': creation_date,\n",
    "            'upsert_date': datetime.utcnow().strftime(zulu_format),\n",
    "            'expiration_date': expiration_date.strftime(zulu_format),\n",
    "            'aux_specific': True,\n",
    "            'public_release': True,\n",
    "            'publication_number': file_name.replace('_', ' '),\n",
    "            'source': None,\n",
    "            'organization': None,\n",
    "            'curator': \"Drew_Wilkins\",\n",
    "            'document_id': compute_pdf_hash(pdf_path),\n",
    "            'file_name': file_name\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metadata_dict_from_pdfs():\n",
    "    '''pulls the metadata from all the pdfs into a dataframe with standard formatting\n",
    "        pdfs in rows and metadata atributes in columns\n",
    "    '''\n",
    "    check_dir_exists(source_directory)\n",
    "\n",
    "    all_pdfs_metadata = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                compute_pdf_hash(pdf_path)\n",
    "                check_pdf_for_issues(pdf_path)\n",
    "                pdf_metadata_dict = get_pdf_metadata(pdf_path)\n",
    "                all_pdfs_metadata[file] = pdf_metadata_dict\n",
    "\n",
    "    return all_pdfs_metadata\n",
    "\n",
    "\n",
    "all_pdfs_metadata = make_metadata_dict_from_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___4JUN2013.pdf': {'title': '006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   4JUN2013', 'leadership_scope': '1_National', 'page_count': 1, 'creation_date': '2019-11-12T14:27Z', 'effective_date': '2019-11-12T14:27Z', 'upsert_date': '2024-01-28T19:51Z', 'expiration_date': '2029-11-12T02:27Z', 'aux_specific': True, 'public_release': True, 'publication_number': '006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   4JUN2013', 'source': None, 'organization': None, 'curator': 'Drew_Wilkins', 'document_id': '869cc57fab30ca4301670b5bc7cb4096', 'file_name': '006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___4JUN2013'}}\n"
     ]
    }
   ],
   "source": [
    "print(all_pdfs_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded with metadata for rows, columns: (1, 15) \n",
      "Inspect first row below....\n",
      "\n",
      "\n",
      "INDEX FOR THIS ROW:             006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___4JUN2013.pdf\n",
      "\n",
      "title                 006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   ...\n",
      "leadership_scope                                             1_National\n",
      "page_count                                                            1\n",
      "creation_date                                         2019-11-12T14:27Z\n",
      "effective_date                                        2019-11-12T14:27Z\n",
      "upsert_date                                           2024-01-28T19:51Z\n",
      "expiration_date                                       2029-11-12T02:27Z\n",
      "aux_specific                                                       True\n",
      "public_release                                                     True\n",
      "publication_number    006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   ...\n",
      "source                                                             None\n",
      "organization                                                       None\n",
      "curator                                                    Drew_Wilkins\n",
      "document_id                            869cc57fab30ca4301670b5bc7cb4096\n",
      "file_name             006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___...\n",
      "Name: 006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___4JUN2013.pdf, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# pulls the metadata from all the pdfs into a dataframe\n",
    "# pdfs in columns and metadata atributes in rows\n",
    "metadata_preview = pd.DataFrame(all_pdfs_metadata).transpose()\n",
    "\n",
    "print(\n",
    "    f\"\"\"Dataframe loaded with metadata for rows, columns: {metadata_preview.shape} \\nInspect first row below....\\n\\n\"\"\")\n",
    "print(f\"\"\"INDEX FOR THIS ROW:             {metadata_preview.index[0]}\\n\"\"\")\n",
    "print(metadata_preview.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " editable excel file has been posted as ../docs/library_catalog/library_doc_catalog_2024-01-28T1953Z.xlsx\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def make_xlsx(metadata_preview):\n",
    "    \"\"\"write dataframe to an Excel file to edit by hand.\"\"\"\n",
    "\n",
    "    now_utc = datetime.utcnow()\n",
    "    file_timestamp = now_utc.strftime('%Y-%m-%dT%H%MZ')\n",
    "    file_path = f'../docs/library_catalog/library_catalog_{file_timestamp}.xlsx'\n",
    "\n",
    "    # Save DataFrame to Excel. Index=True metadata_keys as row 1\n",
    "    # if Index =True then be sure to pd.read_excel( , index_col=0) when you bring it back in\n",
    "    metadata_preview.to_excel(file_path, index=False)\n",
    "    print(f\"\"\" editable excel file has been posted as {file_path}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path, last_update_date = utils.get_most_recent_filepath_and_date(\"library_catalog\", \"docs/library_catalog/\", \"xlsx\")\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "except Exception as e:\n",
    "    os.write(1, f\"Failed to read the Excel file: {e}\\n\".encode())\n",
    "    make_xlsx(metadata_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
