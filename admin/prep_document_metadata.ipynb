{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Extracts PDF metadata to a library catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "%pip install -r requirements.txt\n",
    "# %pip install ipython\n",
    "%pip install pypdf\n",
    "%pip install bs4\n",
    "%pip install requests\n",
    "#%pip install openpyxl\n",
    "%pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This litle code block is used anytime you want to import a local module from within a Jupyter Notebook. This is required becuase Jupyter treats each cell as a module.'''\n",
    "\n",
    "# Navigate up one level from the current notebook's directory to reach the root directory\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:32:50.890 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_source_directory = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/holding back until testing is over/\"\n",
    "library_catalog_directory = \"../docs/library_catalog/\"\n",
    "zulu_format = '%Y-%m-%dT%H:%MZ'\n",
    "leadership_scope = \"1_National\"\n",
    "curator = \"Wilkins,CA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create metadata dictionary\n",
    "\n",
    "def check_dir_exists(pdf_source_directory):\n",
    "    '''Check if the path exists'''\n",
    "    if not os.path.exists(pdf_source_directory):\n",
    "        print(f\"Error: The path '{pdf_source_directory}' does not exist!\")\n",
    "        raise ValueError(f\"The path '{pdf_source_directory}' does not exist!\")\n",
    "\n",
    "\n",
    "def check_pdf_for_issues(pdf_path):\n",
    "    '''\n",
    "    Check if the PDF has issues like being encrypted or corrupt. \n",
    "\n",
    "    If it's encrypted, it will attempt to decrypt using the provided \n",
    "    password (in this case, an empty string). If it's corrupt or if \n",
    "    there's any other issue, it will log the problem and skip the file.  \n",
    "    '''\n",
    "    try:\n",
    "        pdf = PdfReader(pdf_path)\n",
    "        if pdf.is_encrypted:\n",
    "            print(f\"Encryption detected for {pdf_path}\")\n",
    "            pdf.decrypt(\"\")\n",
    "            print(f\"All pages accessed: {len(pdf.pages)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Issue with {pdf_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def remove_multiple_extensions(file_name):\n",
    "    while os.path.splitext(file_name)[1]:\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "    return file_name\n",
    "\n",
    "\n",
    "\n",
    "def get_pdf_metadata(pdf_path):\n",
    "    '''Extract all metadata fields present in the PDF file \n",
    "    along with page count and the hash into a dictionary.'''\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PdfReader(f)\n",
    "        metadata = reader.metadata\n",
    "        file_name = remove_multiple_extensions(os.path.basename(pdf_path))\n",
    "        CreationDate = metadata.get('/CreationDate', '')[2:16]\n",
    "        creation_date = datetime.strptime(\n",
    "            CreationDate, '%Y%m%d%H%M%S') if CreationDate else datetime.utcnow()\n",
    "        expiration_date = creation_date + timedelta(days=365.25 * 10)\n",
    "        creation_date = creation_date.strftime(zulu_format)\n",
    "        return {\n",
    "            'title': metadata.get('/Title', file_name.replace('_', ' ')),\n",
    "            'leadership_scope': leadership_scope,\n",
    "            'page_count': len(reader.pages),\n",
    "            'creation_date': creation_date,\n",
    "            'effective_date': creation_date,\n",
    "            'tagged_date': \"\",\n",
    "            'upsert_date': datetime.utcnow().strftime(zulu_format),\n",
    "            'expiration_date': expiration_date.strftime(zulu_format),\n",
    "            'lifecycle': \"\",  # set during hand edit\n",
    "            'aux_specific': True,\n",
    "            'public_release': True,\n",
    "            'publication_number': file_name.replace('_', ' '),\n",
    "            'source': None,\n",
    "            'organization': None,\n",
    "            'curator': curator,\n",
    "            'document_id': utils.compute_doc_id(pdf_path),\n",
    "            'file_name': file_name,\n",
    "            # 'pdf_path': pdf_path,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___4JUN2013.pdf': {'title': '006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   4JUN2013', 'leadership_scope': '1_National', 'page_count': 1, 'creation_date': '2019-11-12T14:27Z', 'effective_date': '2019-11-12T14:27Z', 'tagged_date': '', 'upsert_date': '2024-01-30T20:32Z', 'expiration_date': '2029-11-12T02:27Z', 'lifecycle': '', 'aux_specific': True, 'public_release': True, 'publication_number': '006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   4JUN2013', 'source': None, 'organization': None, 'curator': 'Wilkins,CA', 'document_id': UUID('bd221a94-cd9a-50ec-8364-6b4ac201ebc7'), 'file_name': '006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___4JUN2013'}}\n"
     ]
    }
   ],
   "source": [
    "def make_metadata_dict_from_pdfs():\n",
    "    '''pulls the metadata from all the pdfs into a dataframe with standard formatting\n",
    "        pdfs in rows and metadata atributes in columns\n",
    "    '''\n",
    "    check_dir_exists(pdf_source_directory)\n",
    "\n",
    "    all_pdfs_metadata = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(pdf_source_directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                check_pdf_for_issues(pdf_path)\n",
    "                utils.compute_doc_id(pdf_path)\n",
    "                pdf_metadata_dict = get_pdf_metadata(pdf_path)\n",
    "                all_pdfs_metadata[file] = pdf_metadata_dict\n",
    "\n",
    "    return all_pdfs_metadata\n",
    "\n",
    "\n",
    "all_pdfs_metadata = make_metadata_dict_from_pdfs()\n",
    "print(all_pdfs_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe created with 1 rows, 17 columns\n"
     ]
    }
   ],
   "source": [
    "# pull the metadata from all the pdfs into a dataframe\n",
    "\n",
    "new_metadata_df = pd.DataFrame(all_pdfs_metadata).transpose()\n",
    "print(\n",
    "    f\"Dataframe created with {new_metadata_df.shape[0]} rows, {new_metadata_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Append New PDF Metadata to Library Catalog and save to a New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xlsx(df: pd.DataFrame, file_name, directory_name) -> None:\n",
    "    \"\"\"A generic function that writes a dataframe to a new Excel file.\"\"\"\n",
    "\n",
    "    now_utc = datetime.utcnow()\n",
    "    # inside function to prevent accidental file overwrites\n",
    "    timestamp = now_utc.strftime('%Y-%m-%dT%H%MZ')\n",
    "    file_path = f'{directory_name}{file_name}{timestamp}.xlsx'\n",
    "\n",
    "    # Save DataFrame to Excel. Index=True metadata_keys as row 1\n",
    "    # if Index =True then be sure to pd.read_excel( , index_col=0) when you bring it back in\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(f\"\"\"Successfully exported:  {file_path}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported:  ../docs/library_catalog/library_catalog_2023-12-19T1900Z.xlsx\n",
      "Dataframe created with 251 rows, 17 columns\n"
     ]
    }
   ],
   "source": [
    "catalog_file_path, last_update_date = utils.get_most_recent_filepath_and_date(\n",
    "    \"library_catalog\", library_catalog_directory, \"xlsx\")\n",
    "\n",
    "try:\n",
    "    most_recent_catalog_df = pd.read_excel(catalog_file_path)\n",
    "    print(f\"Successfully imported:  {catalog_file_path}\")\n",
    "    print(\n",
    "        f\"\"\"Dataframe created with {most_recent_catalog_df.shape[0]} rows, {most_recent_catalog_df.shape[1]} columns\"\"\")\n",
    "except Exception as e:\n",
    "    os.write(\n",
    "        1, f\"Failed to read the most recent library catalog file: {e}\\n\".encode())\n",
    "    os.write(1, f\"Cannot append so saving as new catalog file: {e}\\n\".encode())\n",
    "    make_xlsx(new_metadata_df, \"library_catalog\", library_catalog_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported:  ../docs/library_catalog/library_catalog2024-01-30T2033Z.xlsx\n",
      "Sucessfully appended data to new file. \n",
      "Add/edit the metadata of the appended rows befor ingesting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>leadership_scope</th>\n",
       "      <th>page_count</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>effective_date</th>\n",
       "      <th>tagged_date</th>\n",
       "      <th>upsert_date</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>lifecycle</th>\n",
       "      <th>aux_specific</th>\n",
       "      <th>public_release</th>\n",
       "      <th>publication_number</th>\n",
       "      <th>source</th>\n",
       "      <th>organization</th>\n",
       "      <th>curator</th>\n",
       "      <th>document_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auxiliary Awards Primer</td>\n",
       "      <td>1_National</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-02-22T0000Z</td>\n",
       "      <td>2016-02-22T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2026-02-21T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Microsoft Word - A-PRIMER-FEB16.docx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>ffe70479c5f8f753b5b7be77c7a3fda2</td>\n",
       "      <td>AUX-AWARDS-PRIMER-FEB16.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COAST GUARD AUXILIARY AIDS TO NAVIGATION PROGRAM</td>\n",
       "      <td>1_National</td>\n",
       "      <td>11</td>\n",
       "      <td>1995-06-05T0000Z</td>\n",
       "      <td>1995-06-05T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-31T0000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>CI 16500.16A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>6bc832bbf5802496f1cd9ff98ece22f3</td>\n",
       "      <td>Auxiliary Aids to Navigation Program CI_16500_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Introduction to Marine Safety and Environmenta...</td>\n",
       "      <td>1_National</td>\n",
       "      <td>101</td>\n",
       "      <td>2022-08-17T0000Z</td>\n",
       "      <td>2022-08-17T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-32T0000Z</td>\n",
       "      <td>2032-08-16T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>178c47ff5ff6cb3613dafdf11a253ee1</td>\n",
       "      <td>Auxiliary_Intro_to_Marine_Safety_and_Environme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auxiliary Operations Process Guide Volume II-A...</td>\n",
       "      <td>1_National</td>\n",
       "      <td>195</td>\n",
       "      <td>2023-08-10T0000Z</td>\n",
       "      <td>2023-08-10T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-33T0000Z</td>\n",
       "      <td>2033-08-09T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>AOPG 16798.32A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>a55e809e39b7704cd37de85569f0e1cf</td>\n",
       "      <td>Auxiliary_Operations_Process_Guide_Volume_II-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auxiliary Operations Process Guide Volume III-...</td>\n",
       "      <td>1_National</td>\n",
       "      <td>51</td>\n",
       "      <td>2023-08-04T0000Z</td>\n",
       "      <td>2023-08-04T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-34T0000Z</td>\n",
       "      <td>2033-08-03T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>AOPG 16798.33A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>e68f4897623b255d6553976bcfe6ef07</td>\n",
       "      <td>Auxiliary_Operations_Process_Guide_Volume_III-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>13 19 CHIEF DIRECTOR FINAL ACTION ON NATIONAL ...</td>\n",
       "      <td>1_National</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-278T0000Z</td>\n",
       "      <td>2029-10-14T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ALAUX_13 19</td>\n",
       "      <td>cgaux.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>442d774a36d629a9094fa5e2d39c6739</td>\n",
       "      <td>13_19_CHIEF_DIRECTOR_FINAL_ACTION_ON_NATIONAL_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>06 19 AUXILIARY HUMANITARIAN SERVICE AWARD</td>\n",
       "      <td>1_National</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-279T0000Z</td>\n",
       "      <td>2029-10-14T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ALAUX_06 19</td>\n",
       "      <td>cgaux.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>8fb7d67a8e84b3ac31a1dff9200b07dd</td>\n",
       "      <td>06_19_AUXILIARY_HUMANITARIAN_SERVICE_AWARD.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>11 19 CELL PHONE USE ONBOARD AUXILIARY FACILITIES</td>\n",
       "      <td>1_National</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-280T0000Z</td>\n",
       "      <td>2029-10-14T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ALAUX_11 19</td>\n",
       "      <td>cgaux.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>52f580e4f4fde8cbf9d175451bdb09bd</td>\n",
       "      <td>11_19_CELL_PHONE_USE_ONBOARD_AUXILIARY_FACILIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>01 19 RISK MANAGEMENT TRAINING REQUIREMENTS FO...</td>\n",
       "      <td>1_National</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2019-10-15T0000Z</td>\n",
       "      <td>2023-10-30T0000Z</td>\n",
       "      <td>2023-10-281T0000Z</td>\n",
       "      <td>2029-10-14T0000Z</td>\n",
       "      <td>upserted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ALAUX_01 19</td>\n",
       "      <td>cgaux.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drew_Wilkins</td>\n",
       "      <td>eb067d4f3f1cafc66a7c128b7649c1ec</td>\n",
       "      <td>01_19_RISK_MANAGEMENT_TRAINING_REQUIREMENTS_FO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   ...</td>\n",
       "      <td>1_National</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-12T14:27Z</td>\n",
       "      <td>2019-11-12T14:27Z</td>\n",
       "      <td></td>\n",
       "      <td>2024-01-30T20:32Z</td>\n",
       "      <td>2029-11-12T02:27Z</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Wilkins,CA</td>\n",
       "      <td>bd221a94-cd9a-50ec-8364-6b4ac201ebc7</td>\n",
       "      <td>006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title leadership_scope  \\\n",
       "0                              Auxiliary Awards Primer       1_National   \n",
       "1     COAST GUARD AUXILIARY AIDS TO NAVIGATION PROGRAM       1_National   \n",
       "2    Introduction to Marine Safety and Environmenta...       1_National   \n",
       "3    Auxiliary Operations Process Guide Volume II-A...       1_National   \n",
       "4    Auxiliary Operations Process Guide Volume III-...       1_National   \n",
       "..                                                 ...              ...   \n",
       "247  13 19 CHIEF DIRECTOR FINAL ACTION ON NATIONAL ...       1_National   \n",
       "248         06 19 AUXILIARY HUMANITARIAN SERVICE AWARD       1_National   \n",
       "249  11 19 CELL PHONE USE ONBOARD AUXILIARY FACILITIES       1_National   \n",
       "250  01 19 RISK MANAGEMENT TRAINING REQUIREMENTS FO...       1_National   \n",
       "251  006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   ...       1_National   \n",
       "\n",
       "    page_count      creation_date     effective_date       tagged_date  \\\n",
       "0           20   2016-02-22T0000Z   2016-02-22T0000Z  2023-10-30T0000Z   \n",
       "1           11   1995-06-05T0000Z   1995-06-05T0000Z  2023-10-30T0000Z   \n",
       "2          101   2022-08-17T0000Z   2022-08-17T0000Z  2023-10-30T0000Z   \n",
       "3          195   2023-08-10T0000Z   2023-08-10T0000Z  2023-10-30T0000Z   \n",
       "4           51   2023-08-04T0000Z   2023-08-04T0000Z  2023-10-30T0000Z   \n",
       "..         ...                ...                ...               ...   \n",
       "247          1   2019-10-15T0000Z   2019-10-15T0000Z  2023-10-30T0000Z   \n",
       "248          1   2019-10-15T0000Z   2019-10-15T0000Z  2023-10-30T0000Z   \n",
       "249          3   2019-10-15T0000Z   2019-10-15T0000Z  2023-10-30T0000Z   \n",
       "250          1   2019-10-15T0000Z   2019-10-15T0000Z  2023-10-30T0000Z   \n",
       "251          1  2019-11-12T14:27Z  2019-11-12T14:27Z                     \n",
       "\n",
       "           upsert_date    expiration_date lifecycle aux_specific  \\\n",
       "0     2023-10-30T0000Z   2026-02-21T0000Z  upserted         True   \n",
       "1     2023-10-31T0000Z                NaN  upserted         True   \n",
       "2     2023-10-32T0000Z   2032-08-16T0000Z  upserted         True   \n",
       "3     2023-10-33T0000Z   2033-08-09T0000Z  upserted         True   \n",
       "4     2023-10-34T0000Z   2033-08-03T0000Z  upserted         True   \n",
       "..                 ...                ...       ...          ...   \n",
       "247  2023-10-278T0000Z   2029-10-14T0000Z  upserted         True   \n",
       "248  2023-10-279T0000Z   2029-10-14T0000Z  upserted         True   \n",
       "249  2023-10-280T0000Z   2029-10-14T0000Z  upserted         True   \n",
       "250  2023-10-281T0000Z   2029-10-14T0000Z  upserted         True   \n",
       "251  2024-01-30T20:32Z  2029-11-12T02:27Z                   True   \n",
       "\n",
       "    public_release                                 publication_number  \\\n",
       "0             True               Microsoft Word - A-PRIMER-FEB16.docx   \n",
       "1             True                                       CI 16500.16A   \n",
       "2             True                                                NaN   \n",
       "3             True                                     AOPG 16798.32A   \n",
       "4             True                                     AOPG 16798.33A   \n",
       "..             ...                                                ...   \n",
       "247           True                                       ALAUX_13 19    \n",
       "248           True                                       ALAUX_06 19    \n",
       "249           True                                       ALAUX_11 19    \n",
       "250           True                                       ALAUX_01 19    \n",
       "251           True  006 13 CAMPAIGN TO ELIMINATE SEXUAL ASSAULT   ...   \n",
       "\n",
       "        source organization       curator  \\\n",
       "0          NaN          NaN  Drew_Wilkins   \n",
       "1          NaN          NaN  Drew_Wilkins   \n",
       "2          NaN          NaN  Drew_Wilkins   \n",
       "3          NaN          NaN  Drew_Wilkins   \n",
       "4          NaN          NaN  Drew_Wilkins   \n",
       "..         ...          ...           ...   \n",
       "247  cgaux.org          NaN  Drew_Wilkins   \n",
       "248  cgaux.org          NaN  Drew_Wilkins   \n",
       "249  cgaux.org          NaN  Drew_Wilkins   \n",
       "250  cgaux.org          NaN  Drew_Wilkins   \n",
       "251       None         None    Wilkins,CA   \n",
       "\n",
       "                              document_id  \\\n",
       "0        ffe70479c5f8f753b5b7be77c7a3fda2   \n",
       "1        6bc832bbf5802496f1cd9ff98ece22f3   \n",
       "2        178c47ff5ff6cb3613dafdf11a253ee1   \n",
       "3        a55e809e39b7704cd37de85569f0e1cf   \n",
       "4        e68f4897623b255d6553976bcfe6ef07   \n",
       "..                                    ...   \n",
       "247      442d774a36d629a9094fa5e2d39c6739   \n",
       "248      8fb7d67a8e84b3ac31a1dff9200b07dd   \n",
       "249      52f580e4f4fde8cbf9d175451bdb09bd   \n",
       "250      eb067d4f3f1cafc66a7c128b7649c1ec   \n",
       "251  bd221a94-cd9a-50ec-8364-6b4ac201ebc7   \n",
       "\n",
       "                                             file_name  \n",
       "0                          AUX-AWARDS-PRIMER-FEB16.pdf  \n",
       "1    Auxiliary Aids to Navigation Program CI_16500_...  \n",
       "2    Auxiliary_Intro_to_Marine_Safety_and_Environme...  \n",
       "3    Auxiliary_Operations_Process_Guide_Volume_II-A...  \n",
       "4    Auxiliary_Operations_Process_Guide_Volume_III-...  \n",
       "..                                                 ...  \n",
       "247  13_19_CHIEF_DIRECTOR_FINAL_ACTION_ON_NATIONAL_...  \n",
       "248     06_19_AUXILIARY_HUMANITARIAN_SERVICE_AWARD.pdf  \n",
       "249  11_19_CELL_PHONE_USE_ONBOARD_AUXILIARY_FACILIT...  \n",
       "250  01_19_RISK_MANAGEMENT_TRAINING_REQUIREMENTS_FO...  \n",
       "251  006_13_CAMPAIGN_TO_ELIMINATE_SEXUAL_ASSAULT___...  \n",
       "\n",
       "[252 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def append_dataframes(df1: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df1.columns.equals(df2.columns):\n",
    "        return pd.concat([df1, df2], ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"DataFrames do not have the same columns\")\n",
    "\n",
    "\n",
    "def check_for_duplicates(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    duplicates = df.duplicated(subset=column_name, keep=False)\n",
    "    return df[duplicates]\n",
    "\n",
    "\n",
    "def compare_dfs(df1, df2):\n",
    "    '''a utility to find redundant PDFs, if needed\n",
    "\n",
    "    usage\n",
    "        compare_dfs(new_metadata_df, most_recent_catalog_df)\n",
    "    '''\n",
    "\n",
    "    columns_df1 = set(df1.columns)\n",
    "    columns_df2 = set(df2.columns)\n",
    "    unique_to_df1 = columns_df1.difference(columns_df2)\n",
    "    print(f\"Columns unique to the first DataFrame: {unique_to_df1}\")\n",
    "    unique_to_df2 = columns_df2.difference(columns_df1)\n",
    "    print(f\"Columns unique to the second DataFrame: {unique_to_df2}\")\n",
    "\n",
    "\n",
    "def append_new_metadata_check_and_export(most_recent_catalog_df, new_metadata_df, directory, file_name):\n",
    "    try:\n",
    "        new_catalog_df = append_dataframes(\n",
    "            most_recent_catalog_df, new_metadata_df)\n",
    "        duplicate_rows = check_for_duplicates(new_catalog_df, 'document_id')\n",
    "\n",
    "        if not duplicate_rows.empty:\n",
    "            logging.warning(\n",
    "                \"Duplicate document IDs found. Use compare_dfs utility function to find and remove\")\n",
    "            logging.info(duplicate_rows)\n",
    "\n",
    "        make_xlsx(new_catalog_df, file_name, directory)\n",
    "        os.write(\n",
    "            1, \"Sucessfully appended data to new file. \\nAdd/edit the metadata of the appended rows befor ingesting.\\n\".encode())\n",
    "        return new_catalog_df\n",
    "\n",
    "    except ValueError as e:\n",
    "        logging.error(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "append_new_metadata_check_and_export(\n",
    "    most_recent_catalog_df, new_metadata_df, library_catalog_directory, \"library_catalog_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
