{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  This is the process for grabbing the pdfs and getting them in the form to be chunked and ingested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It includes the custom metadata we are going to use. The custom metadata list is defined in this code block at the bottom. Custom fields can be defined in the custom_fields list. The functions take the list as an argument and  checks for the additional custom metadata fields and includes them in the CSV if they are present in the PDF files.\n",
    "##### THis identifies potential duplicate PDF files, you can compute a hash (e.g., SHA-256) for each file and compare these values. Files with the same hash value are very likely to be duplicates.  \n",
    "##### With the check_pdf_issues function in place, before attempting to get metadata from a PDF, the script will first check if the PDF has issues like being encrypted or corrupt. If it's encrypted, it will attempt to decrypt using the provided password (in this case, an empty string). If it's corrupt or if there's any other issue, it will log the problem and skip the file.  \n",
    "##### The CSV includes  a 'Page Count' column showing the number of pages in each PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade pip\n",
    "\n",
    "#%pip install bs4\n",
    "#%pip install requests\n",
    "#%pip install openpyxl\n",
    "#%pip install tabulate\n",
    "\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime, date, timedelta\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create metadata dictionary \n",
    "# Check if the path exists\n",
    "def check_dir_exists(source_directory):\n",
    "    if not os.path.exists(source_directory):\n",
    "        print(f\"Error: The path '{source_directory}' does not exist!\")\n",
    "        raise ValueError(f\"The path '{source_directory}' does not exist!\")\n",
    "    \n",
    "\n",
    "\n",
    "def compute_pdf_hash(pdf_path):\n",
    "    '''generate a unique hash for the PDF file'''\n",
    "    doc_id = hashlib.md5()\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        for block in iter(lambda: f.read(4096), b\"\"):\n",
    "            doc_id.update(block)\n",
    "    return doc_id.hexdigest()\n",
    "\n",
    "\n",
    "\n",
    "def check_pdf_issues(pdf_path):\n",
    "    try:\n",
    "        pdf = PdfReader(pdf_path)\n",
    "        if pdf.is_encrypted:\n",
    "            print(f\"Encryption detected for {pdf_path}\")\n",
    "            pdf.decrypt(\"\")\n",
    "            print(f\"All pages accessed: {len(pdf.pages)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Issue with {pdf_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def get_pdf_metadata(pdf_path):\n",
    "    '''extract all metadata fields present in the PDF file \n",
    "    along with page count and the hash into a dictionary\n",
    "    '''\n",
    "    pdf_metadata = {}\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PdfReader(f)\n",
    "        existing_pdf_metadata = reader.metadata\n",
    "        # existing pdf metadata code deleted from here\n",
    "        \n",
    "        # Create the pdf metadata\n",
    "        file_name = os.path.basename(pdf_path)\n",
    "        while '.' in file_name:\n",
    "            file_name = os.path.splitext(file_name)[0]   #loop to remove mult extensions\n",
    "        pdf_metadata['Title'] = existing_pdf_metadata.get('/Title')\n",
    "        if not pdf_metadata['Title']:\n",
    "            pdf_metadata['Title'] = file_name.replace('_', ' ')\n",
    "        pdf_metadata['LeadershipScope'] = \"1_National\"\n",
    "        pdf_metadata['PageCount'] = len(reader.pages) # Add page count\n",
    "        creation_date_str = existing_pdf_metadata.get('/CreationDate', '')[2:10]\n",
    "        if creation_date_str:\n",
    "            created_date = datetime.strptime(creation_date_str, '%Y%m%d')\n",
    "        else:\n",
    "            created_date = date.today()\n",
    "        pdf_metadata['CreationDate'] = created_date.strftime('%Y-%m-%d')\n",
    "        pdf_metadata['EffectiveDate'] = created_date.strftime('%Y-%m-%d')\n",
    "        pdf_metadata['IngestDate'] = date.today().strftime('%Y-%m-%d')\n",
    "        expiration_date = created_date + timedelta(days=365.25*10)\n",
    "        pdf_metadata['ExpirationDate'] = expiration_date.strftime('%Y-%m-%d')\n",
    "        pdf_metadata['AuxSpecific'] = True\n",
    "        pdf_metadata['PublicRelease'] = True\n",
    "        pdf_metadata['PublicationNumber'] = pdf_metadata['Title']\n",
    "        pdf_metadata['Source'] = None\n",
    "        pdf_metadata['Organization'] = None # not curently used. Can be CG Org or Unit Number\n",
    "        #pdf_metadata['Curator'] = \"Drew_Wilkins\"\n",
    "        #pdf_metadata['DocId'] = compute_pdf_hash(pdf_path) # Compute and add the hash of the PDF\n",
    "        pdf_metadata['FileName'] = file_name  # add the filename\n",
    "        pdf_metadata['pdf_path'] = pdf_path   #this metadata is needed to write the metadata back to the pdfs  \n",
    "    return pdf_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metadata_dict_from_pdfs():\n",
    "    '''pulls the metadata from all the pdfs into a dataframe with standard formatting\n",
    "        pdfs in rows and metadata atributes in columns\n",
    "    \n",
    "    '''\n",
    "    check_dir_exists(initial_queue_dir)\n",
    "\n",
    "    pdfs_metadata = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(initial_queue_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                compute_pdf_hash(pdf_path)\n",
    "                check_pdf_issues(pdf_path)\n",
    "                pdf_metadata_dict = get_pdf_metadata(pdf_path)\n",
    "                pdfs_metadata[file] = pdf_metadata_dict\n",
    "    \n",
    "    return pdfs_metadata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHeck the metadata dictionary before writing to edit_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_queue_dir = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/PDF_initial_queue\"\n",
    "pdfs_metadata = make_metadata_dict_from_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\nBased on this dictionary...\\n {pdfs_metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls the metadata from all the pdfs into a dataframe with standard formatting\n",
    "#pdfs in rows and metadata atributes in columns\n",
    "pdfs_df_edit_me = pd.DataFrame(pdfs_metadata).transpose()\n",
    "\n",
    "print(f\"\"\"Dataframe loaded with metadata for rows, columns: {pdfs_df_edit_me.shape} \\nInspect first row below....\\n\\n\"\"\")\n",
    "print(f\"\")\n",
    "# transpose to pdfs in rows and metadata in columns\n",
    "# pdfs_df_edit_me = pdfs_df.transpose()\n",
    "\n",
    "print(f\"\"\"INDEX FOR THIS ROW:             {pdfs_df_edit_me.index[0]}\\n\"\"\")\n",
    "print(pdfs_df_edit_me.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def make_xlsx(pdfs_df_edit_me):\n",
    "    \"\"\"write dataframe to an Excel file to edit by hand.\"\"\"\n",
    "    \n",
    "    # Get the current date and time in Zulu (UTC) time\n",
    "    now_utc = datetime.utcnow()\n",
    "    timestamp = now_utc.strftime('%d%b%Y-%H%M')\n",
    "    \n",
    "    # Specify the relative path to save the Excel file with the timestamp appended\n",
    "    file_path = f'../data/PDF_initial_queue/pdfs_edit_me_{timestamp}.xlsx'\n",
    "    \n",
    "    # Save DataFrame to Excel. Index=True metadata_keys as row 1\n",
    "    # if Index =True then be sure to pd.read_excel( , index_col=0) when you bring it back in\n",
    "    pdfs_df_edit_me.to_excel(file_path, index=True)\n",
    "\n",
    "make_xlsx(pdfs_df_edit_me)\n",
    "\n",
    "print(f\"\"\" editable excel file has been posted as /data/PDF_initial_queue/ \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: green;\">Add the medata by hand into the spreadsheet and save it to new name pdfs_edited.xlsx</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\">>>>>> EDIT THE SPREADSHEET pdfs_df_edit_me NOW <<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: green;\">Import the completed Excel file back in as a dataframe</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xlsx_to_df():\n",
    "    \"\"\"Load the hand-edited Excel file into a DataFrame.\"\"\"\n",
    "    \n",
    "    # Search for Excel files that start with 'pdfs_edited_' in the specified directory\n",
    "    files = glob.glob('../data/PDF_initial_queue/pdfs_edited_*.xlsx')\n",
    "\n",
    "    # Check if any files were found\n",
    "    if files:\n",
    "        # Take the first file from the list (assuming there's only one file that matches the pattern)\n",
    "        file_path = files[0]\n",
    "        \n",
    "        # Read the Excel file into a DataFrame; set index_col=0 if index=True when it was dict was dataframed\n",
    "        pdfs_processed_metadata_df = pd.read_excel(file_path, index_col=0)\n",
    "        \n",
    "        # Check if the DataFrame has values\n",
    "        if not pdfs_processed_metadata_df.empty:\n",
    "            print(f\"Successfully loaded the file contents from {file_path} into a DataFrame.\")\n",
    "            print(\"The DataFrame has values in it:\")\n",
    "            print(pdfs_processed_metadata_df)\n",
    "        else:\n",
    "            print(f\"Loaded the file from {file_path}, but the DataFrame is empty.\")\n",
    "        \n",
    "        return pdfs_processed_metadata_df\n",
    "    else:\n",
    "        print(\"No matching Excel file found!\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "\n",
    "# Call the function and store the result in the specified DataFrame\n",
    "pdfs_processed_metadata_df = load_xlsx_to_df()\n",
    "\n",
    "#check the head of the dataframe to make sure the keys oook correct\n",
    "print(pdfs_processed_metadata_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect metadata in a few ways before creating all the new pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the head of the dataframe doesn't look correct, try this\n",
    "#pdfs_processed_metadata_df.set_index('Unnamed: 0', inplace=True)\n",
    "#check the head of the dataframe to make sure the keys look correct\n",
    "print(pdfs_processed_metadata_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts this back into a dictionary of dictionaries (each pdf has a dictionary of metadata) to dicitonary and check dictionary to make sure the keys are there\n",
    "pdfs_processed_metadata_dict = pdfs_processed_metadata_df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs_processed_metadata_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Save to new pdf files</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfWriter, PdfReader\n",
    "import os\n",
    "\n",
    "def write_metadata_to_pdfs(pdfs_processed_metadata_dict, output_dir):\n",
    "    '''write new metadata values out to new pdfs'''\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    print(\"Files to write...\")\n",
    "    \n",
    "    # Initialize a counter for the number of files written\n",
    "    files_written_count = 0\n",
    "    \n",
    "    for file, metadata in pdfs_processed_metadata_dict.items():\n",
    "        pdf_path = metadata['pdf_path']\n",
    "        \n",
    "        # Determine the output path for the updated PDF\n",
    "        output_path = os.path.join(output_dir, os.path.basename(pdf_path))\n",
    "        print(output_path)\n",
    "        \n",
    "        # Read the original PDF\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = PdfReader(f)\n",
    "            writer = PdfWriter()\n",
    "            \n",
    "            # Copy all the pages to the writer object\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                writer.add_page(page)\n",
    "            \n",
    "            # Prep the metadata and write it to the writer object (excluding only the pdf_path field)\n",
    "            metadata_to_write = {f\"/{key}\" if not key.startswith('/') else key: value for key, value in metadata.items() if key != 'pdf_path'}\n",
    "            print(metadata_to_write)\n",
    "            writer.add_metadata(metadata_to_write)\n",
    "            \n",
    "            with open(output_path, 'wb') as out:\n",
    "                writer.write(out)\n",
    "                \n",
    "            files_written_count += 1\n",
    "\n",
    "\n",
    "    print(f\"\\nTotal number of files written: {files_written_count}:\\n\")\n",
    "                \n",
    "# Call the function to write metadata to PDFs\n",
    "output_dir = '../data/PDF_metadata_complete'\n",
    "write_metadata_to_pdfs(pdfs_processed_metadata_dict, output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the metadata of the files to be sure t worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_pdf(pdf_path):\n",
    "    '''Extract metadata from a single PDF and return it as a dictionary.'''\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PdfReader(f)\n",
    "        metadata = reader.metadata\n",
    "        # Convert the metadata to a cleaner dictionary format\n",
    "        clean_metadata = {key[1:] if key.startswith('/') else key: value for key, value in metadata.items()}\n",
    "        return clean_metadata\n",
    "\n",
    "def extract_metadata_from_directory(directory):\n",
    "    '''Extract metadata from all PDFs in a directory and return a list of dictionaries.'''\n",
    "    metadata_list = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf'):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                metadata = extract_metadata_from_pdf(pdf_path)\n",
    "                metadata_list.append(metadata)\n",
    "    return metadata_list\n",
    "\n",
    "# Extract metadata from all PDFs in the directory\n",
    "directory = '../data/PDF_metadata_complete'  # Current directory. Modify this to point to your desired directory.\n",
    "metadata_list = extract_metadata_from_directory(directory)\n",
    "\n",
    "# Convert the list of metadata dictionaries to a pandas DataFrame\n",
    "metadata_complete_df = pd.DataFrame(metadata_list)\n",
    "\n",
    "print(metadata_complete_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_pdf_metadata(directory, file_name):\n",
    "    '''Print metadata of a given PDF.'''\n",
    "    pdf_path = os.path.join(directory, file_name)\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PdfReader(f)\n",
    "        doc_info = reader.metadata\n",
    "    \n",
    "    for key, value in doc_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Specify the path to your PDF\n",
    "directory = '../data/PDF_metadata_complete'\n",
    "file_name = '026_20_SOLICITATION_FOR_RESEARCH_DEVELOPMENT_TEST_AND_EVALUATION__RDT_E__IDEAS copy.pdf'\n",
    "\n",
    "print_pdf_metadata(directory, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
