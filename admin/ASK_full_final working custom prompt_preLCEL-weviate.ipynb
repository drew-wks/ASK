{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bda072",
   "metadata": {},
   "source": [
    "## 0. Installs and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip list # See what's installed and versions\n",
    "\n",
    "\n",
    "# %pip install --upgrade langchain\n",
    "# %pip install --upgrade docarray\n",
    "# %pip install python-doten\n",
    "# %pip install --upgrade wandb\n",
    "# %pip install qdrant-client # applies to all qdrant implementations\n",
    "# %pip install pypdf\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730057d3",
   "metadata": {},
   "source": [
    "## 1. Set the model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5540a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "config = {\n",
    "    \"splitter_type\": \"CharacterTextSplitter\",\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": len,\n",
    "    \"separators\": [\"}\"],  # [\" \", \",\", \"\\n\"]\n",
    "    \"embedding\": OpenAIEmbeddings(),\n",
    "    \"embedding_dims\": 1536,\n",
    "    \"search_type\": \"mmr\",\n",
    "    'fetch_k': 20,   # number of documents to pass to the search alg (eg., mmr)\n",
    "    \"k\": 8,  # number of document from fetch to pass to the LLM for inference\n",
    "    'lambda_mult': .7,    # 0= max ccvcetdcdiversity, 1 is max relevance. default is 0.5\n",
    "    \"score_threshold\": 0.5,  # for similarity score\n",
    "    \"model\": \"gpt-3.5-turbo-16k\",  # gpt-4, gpt-3.5-turbo-16k\n",
    "    \"temperature\": 0.7,\n",
    "    \"chain_type\": \"stuff\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Langchain debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea2a89",
   "metadata": {},
   "source": [
    "## 3. Chunk 'n' Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pypdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "def extract_metadata_from_pdfs(path_to_ingest_files):\n",
    "    file_list = []\n",
    "    pages = []\n",
    "    total_size = 0\n",
    "\n",
    "    # Check if the path is a directory or a file\n",
    "    if os.path.isdir(path_to_ingest_files):\n",
    "        print(\"Loading PDFs from directory...\")\n",
    "        for foldername, subfolders, filenames in os.walk(path_to_ingest_files):\n",
    "            for file in filenames:\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    process_pdf(os.path.join(foldername, file),\n",
    "                                file_list, pages, total_size)\n",
    "    elif os.path.isfile(path_to_ingest_files) and path_to_ingest_files.lower().endswith('.pdf'):\n",
    "        print(\"Loading a single PDF file...\")\n",
    "        process_pdf(path_to_ingest_files, file_list, pages, total_size)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Error: The path '{path_to_ingest_files}' is not a valid directory or PDF file!\")\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path, file_list, pages, total_size):\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        for doc in documents:\n",
    "            with open(doc.metadata[\"source\"], \"rb\") as pdf_file_obj:\n",
    "                reader = pypdf.PdfReader(pdf_file_obj)\n",
    "                pdf_metadata = reader.metadata\n",
    "                doc.metadata.update(\n",
    "                    {key: pdf_metadata[key] for key in pdf_metadata.keys()})\n",
    "        pages.extend(documents)\n",
    "        file_list.append(pdf_path.split('/')[-1])\n",
    "        total_size += os.path.getsize(pdf_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {pdf_path}\")\n",
    "    for item in file_list:\n",
    "        print(f\"Processed {item}\")\n",
    "\n",
    "\n",
    "path_to_ingest_files = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/2023-ALAUX\"\n",
    "# path_to_ingest_files = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/PDF_metadata_complete\"\n",
    "# path_to_ingest_files = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/PDF_metadata_complete/test\"\n",
    "# path_to_ingest_files = \"/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/diagnostics/\"\n",
    "pages = extract_metadata_from_pdfs(path_to_ingest_files)\n",
    "if pages:\n",
    "    last_page = pages[-1]\n",
    "else:\n",
    "    print(\"No pages were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab05e49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='23 OC T 2023 \\nFM:  CHDIRAUX  \\nTO:  ALAUX  \\nALAUX 038/23 \\n  Subj:  CREDIT FOR QUALIFICATIONS OF HONORABLY DISCHARGED AND/OR RETIRED COAST GUARD MILITARY PERSONNEL  \\n \\n  1.  Section 4 of ALAUX 015/23 approved credit for the training and qualifications of honorably discharged and/or retired Coast Guard military personnel who enroll in the Auxiliary. The credit applies to any three-year period between a Coast Guard military person’s last currency and their Auxiliary enrollment after they se parate from service.  \\n 2.  To clarify boating safety course and Auxiliary Core Training (AUXCT) completion requirements, Section 4.c.(1)(b) of ALAUX 015/23 is changed to read as follows:   \\n     “(b) The requirement for successful completion of an approved boating safety course and most Auxiliary Core Training (AUXCT) courses may be waived by the DIRAUX for the purpose of conveying any qualification listed in the table below. The BQII course may not be waived. If the boating safety course and AUXCT courses ar e waived, and the BQII \\ncourse is completed, the DIRAUX may then place the Auxiliarist in Basically Qualified (BQ) status and make appropriate notes of waiver in AUXDATA II.”    \\n  3.  This change clarifies that completion of an approved boating safety course along with any AUXCT courses except the BQII course may be waived by the DIRAUX for the subject personnel.    4.  ALAUX 015/23 also approved credit for the Auxiliary Instructor competency to be applied to a full -time instructor at any Coast Guard trainin g center. That credit is expanded to apply to a \\ncurrent Coast Guard Team Coordination Training (CG TCT) Facilitator who falls within the three-year period. Section 4.c.(1)(b)9. is changed as follows:   \\n  \\nIf Possessing This Coast Guard \\nQualification / Rating  Then May Be Granted This \\nAuxiliary Qualification / Status  \\n9 Full-time instructor at any CG \\ntraining center; CG TCT Facilitator  Instructor \\n   5.  Internet release is authorized.', metadata={'source': '/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/ASK/data/2023-ALAUX/038_23_CREDIT_FOR_QUALS_OF_HONORABLY_DISCHARGED_AND_OR_RETIRED_CG_PERSONNEL.pdf', 'page': 0, '/Author': 'Tober, Samantha M YN1', '/Comments': '', '/Company': '', '/ContentTypeId': '0x010100CB76551212F59C40ACA5AFB2CA9DF8AB', '/CreationDate': \"D:20231026144003-04'00'\", '/Creator': 'Acrobat PDFMaker 23 for Word', '/Keywords': '', '/MediaServiceImageTags': '', '/ModDate': \"D:20231026144005-04'00'\", '/Producer': 'Adobe PDF Library 23.6.96', '/SourceModified': 'D:20231026183849', '/Subject': '', '/Title': ''})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# import pdf_concatter as concat\n",
    "\n",
    "\n",
    "# chunks at the page break\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config[\"chunk_size\"],\n",
    "    chunk_overlap=config[\"chunk_overlap\"],\n",
    "    length_function=config[\"length_function\"],\n",
    "    separators=config[\"separators\"]\n",
    ")\n",
    "\n",
    "\n",
    "# concat.pages_to_page(pages) #concatenates all the pages of the pdf into one\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "'''\"chunks\" is a list of objects of the class langchain.schema.document.Document'''\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_document_load_summary():\n",
    "    from pympler import asizeof\n",
    "    import tiktoken\n",
    "\n",
    "    encoding = tiktoken.encoding_for_model(config[\"model\"])\n",
    "    vectorstore_tokens = encoding.encode(str(chunks))\n",
    "    num_vectorestore_tokens = len(vectorstore_tokens)\n",
    "    num_chunks = len(chunks)\n",
    "    # Qudrant's formula is memory_size in bytes = number_of_vectors * vector_dimension * 4 bytes * 1.5\n",
    "    memory_size = num_chunks * config[\"embedding_dims\"] * 4 * 1.5\n",
    "\n",
    "    print(f\"\"\"\n",
    "        Target folder: {path_to_ingest_files}\n",
    "        Pages processed: {len(pages)}\n",
    "        Text splitter: {config[\"splitter_type\"]}\n",
    "        Chunk size: {config[\"chunk_size\"]} characters\n",
    "        Chunk overlap: {config[\"chunk_overlap\"]} characters\n",
    "        Chunks (vectors) created: {num_chunks} \n",
    "        Dictionary size: {asizeof.asizeof(pages) / (1024 * 1024):.2f} MB\n",
    "        Vectorstore tokens: {num_vectorestore_tokens}\n",
    "        Estimated memory size (Qdrant): {memory_size / (1024 * 1024):.2f} MB\n",
    "    \"\"\")\n",
    "\n",
    "    ''' TODO These variables are now in a function so not accessible.    \n",
    "        Document(s)loaded: {len(file_list)}\n",
    "        Load size: {total_size / (1024 * 1024):.2f} MB\n",
    "        '''\n",
    "\n",
    "\n",
    "print_document_load_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937261bc",
   "metadata": {},
   "source": [
    "## 4. OPTIONAL: Create NEW vector store and add documents into it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combo Create + Add Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f66e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --pre -U \"weaviate-client==4.*\"\n",
    "import weaviate\n",
    "\n",
    "\n",
    "api_key = os.environ.get(\"WEVIATE_API_KEY\")\n",
    "weviate_url = os.environ.get(\"WEVIATE_URL\")\n",
    "\n",
    "\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=weviate_url,\n",
    "    auth_credentials=weaviate.AuthApiKey(api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e75c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.weaviate import Weaviate\n",
    "from langchain.vectorstores import Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00612101",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Weaviate.from_documents(\n",
    "    docs, embeddings, weaviate_url=weviate_url, by_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "weviate = Weaviate(client=client,\n",
    "                   index_name=\"ask-vectorstore-3tco7gn4\",\n",
    "                   # embedding here is LC interface to the embedding model\n",
    "                   )\n",
    "\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    documents, embeddings, client=client, by_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant.from_documents(\n",
    "    chunks,\n",
    "    embedding=config[\"embedding\"],  # yes this is required here too\n",
    "    path=qdrant_path,  # Only required for local instance\n",
    "    collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "    # url=os.environ.get(\"QDRANT_URL\"),\n",
    "    # api_key=os.environ.get(\"QDRANT_API_KEY\"), # Only required for Qdrant Cloud\n",
    "    force_recreate=False,  # don't use if db doesn't already exist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "\n",
    "\n",
    "def create_localdb_and_add_docs():\n",
    "    \"\"\"Use only to create the vectore db and load docs the first time. \n",
    "    It overcomes limitations in Langchain by releaseing the vecDB afterwards\"\"\"\n",
    "\n",
    "    client = QdrantClient()\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=qdrant_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "    qdrant.from_documents(\n",
    "        chunks,\n",
    "        embedding=config[\"embedding\"],  # yes this is required here too\n",
    "        path=qdrant_path,  # Only required for local instance\n",
    "        collection_name=qdrant_collection_name,  # yes this is required here too\n",
    "        # url=os.environ.get(\"QDRANT_URL\"),\n",
    "        # Only required for Qdrant Cloud\n",
    "        # api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    "        force_recreate=False,  # don't use if db doesn't already exist\n",
    "    )\n",
    "    # print(client.get_collections())\n",
    "    # print(\n",
    "    # f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")\n",
    "\n",
    "\n",
    "check_me = create_localdb_and_add_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new Qdrant DB / Collection. \n",
    "#### <span style=\"color:red\">WARNING: This will overwrite existing one</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may not work\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "client = QdrantClient(\n",
    "    path=qdrant_path\n",
    ")  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=qdrant_collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "# You may need to delete the lock file to access this afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Documents with Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def add_docs_to_existingdb_with_delay(batch_size, delay):\n",
    "    \"\"\"Use only to create the vectore db and load docs the first time. (7min)\n",
    "    It overcomes limitations in Langchain by releasing the vecDB afterwards.\n",
    "    This version loads the chunks into the vector store with a delay\"\"\"\n",
    "\n",
    "    '''Uses the DocArrayInMemorySearch.add_documents\n",
    "    object method. Aim for ~800K tokens and then have \n",
    "    the timer delay until 60 sec is reached'''\n",
    "\n",
    "    from qdrant_client import QdrantClient\n",
    "    from qdrant_client.http import models\n",
    "    from langchain.vectorstores import Qdrant\n",
    "\n",
    "    client = QdrantClient(\n",
    "        path=qdrant_path\n",
    "    )  # Only required for local instance) #Initializes an entry point to communicate with Qdrant service via REST or gPRC API\n",
    "\n",
    "    # Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "    qdrant = Qdrant(client=client,\n",
    "                    collection_name=qdrant_collection_name,\n",
    "                    # embedding here is LC interface to the embedding model\n",
    "                    embeddings=config[\"embedding\"],\n",
    "                    )\n",
    "\n",
    "    # generate indices starting from 0. increment by batch_size until len(chunks)\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]  # Create a batch of chunks\n",
    "        qdrant.add_documents(documents=batch)  # Add the batch of chunks\n",
    "        # pause time probably don't need to be changed since tokens usually hit limit by 18 sec.\n",
    "        time.sleep(delay)\n",
    "\n",
    "    del qdrant\n",
    "    client.close()    # Release the database from this process\n",
    "    del client\n",
    "\n",
    "\n",
    "add_docs_to_existingdb_with_delay(1700, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_collections())\n",
    "\n",
    "print(\n",
    "    f\"\"\"number of points in collection {client.count(collection_name=qdrant_collection_name,)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1c0a3",
   "metadata": {},
   "source": [
    "## 4. Connect to Vector Store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cdedd8",
   "metadata": {},
   "source": [
    "#### Qdrant Cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae5b082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='ASK_vectorstore')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates an instance of Qdrant Client, which is an entrypoint to communicate with the Qdrant service\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "\n",
    "if 'client' not in globals():\n",
    "    client = QdrantClient(url=os.environ.get(\"QDRANT_URL\"),\n",
    "                          api_key=os.environ.get(\"QDRANT_API_KEY\"))\n",
    "else:\n",
    "    print(f\"Client already exists at {client}\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d6a9e",
   "metadata": {},
   "source": [
    "#### or Qdrant Local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an instance of Qdrant Client, which is an entrypoint to communicate with the Qdrant service. Running this places a lock file in the qdrant directory\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "import psutil\n",
    "\n",
    "if 'client' not in globals():\n",
    "    # Only required for local instance``\n",
    "    client = QdrantClient(path=qdrant_path)\n",
    "else:\n",
    "    print(f\"Client already exists at {client}\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5319661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client is running via a URL.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.local.qdrant_local import QdrantLocal\n",
    "from qdrant_client.qdrant_remote import QdrantRemote\n",
    "\n",
    "try:\n",
    "    # Check if the client is running locally or via a URL\n",
    "    if isinstance(client._client, QdrantLocal):\n",
    "        print(\"The client is running locally.\")\n",
    "    elif isinstance(client._client, QdrantRemote):\n",
    "        print(\"The client is running via a URL.\")\n",
    "    else:\n",
    "        # This else block handles cases where client._client is neither QdrantLocal nor QdrantRemote\n",
    "        print(\"Unable to determine the running mode of the Qdrant client.\")\n",
    "except Exception as e:\n",
    "    # This block catches any other exceptions that might occur\n",
    "    print(\"Unable to determine the running mode of the Qdrant client. Error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77b836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a LangChain \"vector store\" object with entrypoint to your DB within it\n",
    "qdrant = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=qdrant_collection_name,\n",
    "    # embedding here is a LC interface to the embedding model,\n",
    "    embeddings=config[\"embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f01bb",
   "metadata": {},
   "source": [
    "## 5. Initialize a Document Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c065ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a VectorStoreRetriever called retriever from the LC qdrant vector store object\n",
    "\n",
    "# Option 1 using MMR search\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': config[\"k\"], \"fetch_k\": config[\"fetch_k\"],\n",
    "                   \"lambda_mult\": config[\"lambda_mult\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 using k-NN similarity search\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    # search_kwargs={'k': config[\"k\"]}  # k specify number of nearest neighbors\n",
    "    search_kwargs={'score_threshold': config[\"score_threshold\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Test the retriever is functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Title: No Title, Source: References/Gold Side/Auxiliary_Training_Handbook_Boat_Crew_ATH_16794.51B.pdf, Page: 44  \n",
       "Title: No Title, Source: For_injestion/2023 Surface Operations_Workshop Rev1.8.pptx.pdf, Page: 25  \n",
       "Title: No Title, Source: References/Gold Side/Auxiliary_Training_Handbook_Boat_Crew_ATH_16794.51B.pdf, Page: 78  \n",
       "Title: No Title, Source: References/Facilitation Docs/2023 Surface Workshop Rev1.8.pptx.pdf, Page: 34  \n",
       "Title: No Title, Source: References/Facilitation Docs/2023 Surface Workshop Rev1.8.pptx.pdf, Page: 59  \n",
       "Title: No Title, Source: References/Gold Side/Auxiliary_Training_Handbook_Boat_Crew_ATH_16794.51B.pdf, Page: 45  \n",
       "Title: No Title, Source: References/Facilitation Docs/2023 Surface Workshop Rev1.8.pptx.pdf, Page: 35  \n",
       "Title: No Title, Source: References/Gold Side/Auxiliary_Training_Handbook-Aviation_ATH_16798.5A.pdf, Page: 51  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "import re\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"what are the annual currency requirements for boat crew members?\")\n",
    "\n",
    "\n",
    "# Regular expression pattern to match metadata inside parentheses\n",
    "metadata_pattern = re.compile(r\"metadata=\\{(.*?)\\}\")\n",
    "\n",
    "# Function to extract metadata\n",
    "\n",
    "\n",
    "def extract_metadata(doc_list):\n",
    "    metadata_list = []\n",
    "    for doc in doc_list:\n",
    "        # Convert doc to string if it's not already a string\n",
    "        if not isinstance(doc, str):\n",
    "            doc = str(doc)\n",
    "\n",
    "        matches = metadata_pattern.findall(doc)\n",
    "        for match in matches:\n",
    "            # Convert the matched string to a dictionary\n",
    "            metadata_dict = eval('{' + match + '}')\n",
    "            metadata_list.append(metadata_dict)\n",
    "    return metadata_list\n",
    "\n",
    "\n",
    "# Extracting metadata\n",
    "metadata_list = extract_metadata(retrieved_docs)\n",
    "\n",
    "# Print each metadata dictionary as a Markdown list item\n",
    "\n",
    "\n",
    "def display_selected_metadata_as_markdown(metadata_list):\n",
    "    # Start with an empty string\n",
    "    markdown_string = \"\"\n",
    "\n",
    "    # Iterate over each metadata dictionary\n",
    "    for metadata in metadata_list:\n",
    "        # Extract the /Title and page values\n",
    "        title = metadata.get('/Title', 'No Title')\n",
    "        source = metadata.get('source', 'No Source')\n",
    "        page = metadata.get('page', 'No Page')\n",
    "\n",
    "        # Add them as a list item in the markdown string\n",
    "        markdown_string += \"Title: {}, Source: {}, Page: {}  \\n\".format(\n",
    "            title, source, page)\n",
    "\n",
    "    # Display the markdown string\n",
    "    display(Markdown(markdown_string))\n",
    "\n",
    "\n",
    "# Assuming metadata_list is your list of metadata dictionaries\n",
    "display_selected_metadata_as_markdown(metadata_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab1674",
   "metadata": {},
   "source": [
    "## 6. Initialize a Response Generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Simple Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05221adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does QA on the vector store\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# keep outside the function so it's accessible elsewhere in this notebook\n",
    "llm = ChatOpenAI(model=config[\"model\"], temperature=config[\"temperature\"])\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=config[\"chain_type\"],\n",
    "    retriever=retriever,\n",
    "    # chain_type_kwargs={\"prompt\": prompt},# This is how you specify a custom prompt\n",
    "    # callbacks=[tracer], #this is for wandb\n",
    "    return_source_documents=True,\n",
    ")\n",
    "rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "query = \"what are the currency maintenance requirements for copilot?\"\n",
    "\n",
    "\n",
    "response = rag({\"query\": query})\n",
    "\n",
    "\n",
    "print()\n",
    "display(Markdown(f\"### **Question:**\"))\n",
    "display(Markdown(query))\n",
    "display(Markdown(f\"### **Response:**\"))\n",
    "display(Markdown(f\"> <br>{response['result']}<br><br>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Generator with a custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A pilot and copilots is considered a flight crewmember, so requiremnts that apply to all flight crewmmebers also apply to air pilots and copilots. If there are requirements for uniform inspection, AUXCT and risk management training, be sure to include them in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, StuffDocumentsChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "'''The default prompt is:\n",
    "Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say I don't know, don't try to make up an answer.\\n----------------\\n{context}\n",
    "'''\n",
    "\n",
    "\n",
    "system_message_prompt_template = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=['context'],\n",
    "        template=\"Use the following pieces of context to answer the users question. INCLUDES ALL OF THE DETAILS YOU CAN IN YOUR RESPONSE, INDLUDING REQUIREMENTS AND REGULATIONS. If the question is about qualification, certification or currency, then follow these steps: 1. Determine the name of the qualification or certification. 2. Determine whether the question is about initial qualification or currency maintenance. Each have different requirements. 3. Determine what program the qualification or certification belongs to, such as Boat Crew program or Aviation program. 4. Determine any requirements that apply to all positions and certifications in that program as well as the specific requirements for the certification. For example, a Coxswain is a certification in the boat crew program. The Boat Crew program has requirements such as annual surface operations workshop. Additionally, coxswain has the requirement to complete a navigation test. Likewise, A Co-Pilot is a certification in the Aviation program. The Aviation program has requirements for all flight crewmembers that apply to Co-Pilot and First Pilot. First Pilot and Co-Pilot are Pilot flight crew positions, so they have Pilot requirements apply to First Pilot and Co-Pilot. Co-Pilot and First Pilot may have additional requirements specific to their certification. Risk Management Team Coordination Training (RM-TCT) is an annual currency requirement for some certifications such as boat crew program, surface operations, air, and telecommunications. National workshops are annual program requirements in years in which the workshop is specified. All certifications and officer positions require an Auxiliarist be current in Auxiliary Core Training (AUXCT). Crewmember is an Auxiliary certification unless the user states otherwise. \\nIf you don't know the answer, just say I don't know, don't try to make up an answer. \\n----------------\\n{context}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Does QA on the vector store\n",
    "\n",
    "llm = ChatOpenAI(model=config[\"model\"], temperature=config[\"temperature\"])\n",
    "\n",
    "'''Initializes a simple LLMChain chain: a prompt and a model\n",
    "    In this case, the prompt is ChatPromptTemplate (could have used PromptTemplate)\n",
    "    comprised of the system and human prompts and the model is LLM (could have used ChatModels)'''\n",
    "llm_chain = LLMChain(\n",
    "    prompt=ChatPromptTemplate(\n",
    "        input_variables=['context', 'question'],\n",
    "        messages=[\n",
    "            system_message_prompt_template,\n",
    "            HumanMessagePromptTemplate(\n",
    "                prompt=PromptTemplate(\n",
    "                    input_variables=['question'],\n",
    "                    template='{question}'\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "\n",
    "rag = RetrievalQA(\n",
    "    combine_documents_chain=StuffDocumentsChain(\n",
    "        llm_chain=llm_chain, document_variable_name='context'),\n",
    "    return_source_documents=True,\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, StuffDocumentsChain, LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, load_prompt\n",
    "\n",
    "# since this uses ChatPromptTemplate, the _type field in the JSON file is set to \"prompt\".\n",
    "prompt_template = load_prompt(\"generic_prompt_template.json\")\n",
    "\n",
    "llm = ChatOpenAI(model=config[\"model\"], temperature=config[\"temperature\"])\n",
    "\n",
    "'''Initializes a simple LLMChain chain: a prompt and a model\n",
    "    In this case, the prompt is ChatPromptTemplate (could have used PromptTemplate)\n",
    "    comprised of the system and human prompts and the model is LLM (could have used ChatModels)'''\n",
    "llm_chain = LLMChain(\n",
    "    prompt=PromptTemplate.from_template(prompt_template),\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "\n",
    "rag = RetrievalQA(\n",
    "    combine_documents_chain=StuffDocumentsChain(\n",
    "        llm_chain=llm_chain, document_variable_name='context'),\n",
    "    return_source_documents=True,\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e484486",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 6. Search the index and display results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what are the annual currency requirements for boat crewmembers?\"\n",
    "response = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e41d5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### **Question:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> <br>what are the annual currency requirements for boat crewmembers?<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### **Response:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> <br>The annual currency requirements for boat crewmembers are as follows:\n",
       "\n",
       "1. Log 12 hours underway as a crewmember, on orders, each calendar year.\n",
       "2. If certified as both a crewmember and PWC operator, complete 6 hours underway as a crewmember and an additional 12 hours as a PWC operator for a total of 18 hours.\n",
       "3. If a nighttime certified crewmember, at least 2 of the total 12 hours required underway must be performed during nighttime hours.\n",
       "4. Complete the following currency maintenance tasks annually and document them according to Chapter 5, Section A, Paragraph A.6 of the Auxiliary Training Handbook - Boat Crew:\n",
       "   - Perform a Navigation and Piloting Exercise / TASK BCM-08-02-AUX\n",
       "   - Man Overboard\n",
       "   - Assist the Coxswain with a Pre-Check off of an Auxiliary Facility\n",
       "   - Towing Astern\n",
       "   - Towing Alongside\n",
       "   - Boat Handling\n",
       "   - Assist in anchoring and weighing the Boat's Anchor\n",
       "   - Demonstrate proficiency in knot tying and line handling\n",
       "   - Demonstrate procedures to be followed in the event of a fire\n",
       "   - Demonstrate procedures to be followed in the event of a grounding or striking of a submerged object\n",
       "\n",
       "Remember to submit documentation of completed currency maintenance hours and tasks by December 31st of each calendar year in order to maintain certification and avoid being placed into Required Yearly Requirement (REYR) status.<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### **Source Documents:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Auxiliary_Training_Handbook_Boat_Crew_ATH_16794*, page 44<br>\n",
       "\n",
       "*2023 Surface Operations_Workshop Rev1*, page 25<br>\n",
       "\n",
       "*Auxiliary_Training_Handbook_Boat_Crew_ATH_16794*, page 78<br>\n",
       "\n",
       "*2023 Surface Workshop Rev1*, page 35<br>\n",
       "\n",
       "*2023 Surface Workshop Rev1*, page 59<br>\n",
       "\n",
       "*Auxiliary_Training_Handbook_Boat_Crew_ATH_16794*, page 45<br>\n",
       "\n",
       "*Auxiliary_Training_Handbook_Boat_Crew_ATH_16794*, page 47<br>\n",
       "\n",
       "*Auxiliary_Training_Handbook_Boat_Crew_ATH_16794*, page 43<br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def create_short_source_list(response):\n",
    "    '''Extracts a list of sources with no description \n",
    "\n",
    "    response is a dictionary with three keys:\n",
    "    dict_keys(['query', 'result', 'source_documents'])\n",
    "    'source_documents' is a list with a custom object Document \n",
    "    '''\n",
    "\n",
    "    markdown_list = []\n",
    "\n",
    "    for i, doc in enumerate(response['source_documents'], start=1):\n",
    "        page_content = doc.page_content\n",
    "        source = doc.metadata['source']\n",
    "        short_source = source.split('/')[-1].split('.')[0]\n",
    "        page = doc.metadata['page']\n",
    "        markdown_list.append(f\"*{short_source}*, page {page}<br>\\n\")\n",
    "\n",
    "    short_source_list = '\\n'.join(markdown_list)\n",
    "    return short_source_list\n",
    "\n",
    "\n",
    "short_source_list = create_short_source_list(response)\n",
    "\n",
    "# display list\n",
    "print(\"\")\n",
    "display(Markdown(f\"### **Question:**\"))\n",
    "display(Markdown(f\"> <br>{response['query']}<br><br>\"))\n",
    "display(Markdown(f\"### **Response:**\"))\n",
    "display(Markdown(f\"> <br>{response['result']}<br><br>\"))\n",
    "display(Markdown(f\"#### **Source Documents:**\"))\n",
    "display(Markdown(short_source_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "359a9937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### **Full Source References:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Reference 1:**    *Auxiliary_Training_Handbook_Boat_Crew_ATH_16794*, page 44<br>  Auxiliary Training Handbook – Boat Crew  \n",
       "Chapter 5 –  Currency Maintenance \n",
       " \n",
       " \n",
       "5-2 \n",
       "Section A.  Currency Maintenance \n",
       "Introduction  This section discusses the minimum currency requirements for \n",
       "maintaining certifications.  \n",
       "In this Section  This section contains the following information:  \n",
       "Title  Page  \n",
       "General  5-2 \n",
       "Currency Maintenance Cycle  5-2 \n",
       "Crewmember  5-3 \n",
       "Coxswain  5-4 \n",
       "PWC Operator  5-5 \n",
       "Currency Maintenance Documentation Requirement  5-5 \n",
       "Nighttime Defintion  5-5 \n",
       "TCT/RM Training  5-6 \n",
       "Navigation Rules Exam  5-6 \n",
       "Operational Workshops  5-7 \n",
       "Documentation of Training  5-7 \n",
       " \n",
       "  \n",
       "General  Currency requirements consist of a set of tasks that must be performed \n",
       "every year along with annual underway hour requirements. \n",
       "  \n",
       "Currency Maintenance Cycle  Currency maintenance is conducted on a three -year cycle, with certain \n",
       "requirements every year during the cycle, and requires the services of a Qualification Examiner (QE).  \n",
       "The currency cycle begins on 01 January of the year following initial \n",
       "certification. Currency requirements must be met by 31 December of each year.   \n",
       "For example,  if a member is certified as a coxswain on 15 July 2020, that \n",
       "member's first currency year begins  on 01 January 2021, and the member \n",
       "must meet all annual currency requirements by the end of 2021 (31 \n",
       "December 2021). The third- year currency requirements must be met by \n",
       "31 December 202 3.  \n",
       "Annual currency requirements must be met during the first full cale ndar \n",
       "year after certification. Credit will not be given to hours or tasks \n",
       "completed in the partial year of initial certification. Failure to meet \n",
       "currency requirements in any year of the cycle will cause a member's\n",
       "\n",
       "**Reference 2:**    *2023 Surface Operations_Workshop Rev1*, page 25<br>  *** UPDATE***   Annual Training for 2023 \n",
       "Currency requirements consist of a set of tasks that must be \n",
       "performed every year along with annual underway hour \n",
       "requirements. \n",
       "     Reference Auxiliary Training Handbook – Boat Crew (ATH-BC) -      \n",
       "Chapter 5 for detailed qualification, certification, annual \n",
       "currency maintenance, and 3-year QE requirements for crew \n",
       "member, coxswain, and PWC operator. \n",
       "     Detailed reporting and tracking procedures will be released via \n",
       "     ALAUX in early 2023. \n",
       "Response Division – 2023 Surface \n",
       "Workshop U.S COAST GUARD AUXILIARY - UNCLASSIFIED 26\n",
       "\n",
       "**Reference 3:**    *Auxiliary_Training_Handbook_Boat_Crew_ATH_16794*, page 78<br>  Auxiliary Training Handbook – Boat Crew  \n",
       "Enclosure (4)  \n",
       " \n",
       " \n",
       "2 \n",
       "Member ID:   Task Currency Calendar Year:   \n",
       "Persons authorized to sign off on Tasks completed shall record their name, signature, and initials in the table below.  \n",
       "Sign Off Name  Sign Off Signature  Sign Off  \n",
       "Initials  \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "ROLLUP TASK NAMES IN AUXDATA II  \n",
       "The Annual Currency Maintenance Tasks shall be recorded in AUXDATA II as the rollup Tasks listed below, \n",
       "acknowledging all Tasks within a requirement section are complete:  \n",
       "• (BCM) ANNUAL DAY TASKS  \n",
       "• (BCM) ANNUAL NIGHT TASKS  \n",
       "• (BCM) ANNUAL NIGHT U/W HOURS  \n",
       "ROLLUP TASK DATES  IN AUXDATA II  \n",
       "When all Annual  Currency Maintenance Tasks within a requirement section are completed within the designated Task \n",
       "Currency Calendar Year, the Task completion date for the rollup Task shall be recorded in AUXDATA II as the latest \n",
       "date lis ted in the corresponding requirement section.  \n",
       "If one or more Currency Maintenance Tasks are completed for a requirement section after the designated Task Currency Calendar Year, the Task completion date for the rollup Task shall be recorded in AUXDATA II a s December \n",
       "31\n",
       "st of the Task Currency Calendar Year listed on this form regardless of the latest date listed in the corresponding \n",
       "requirement section. Example:  \n",
       "• Task Currency Calendar Year = 2023  \n",
       "• One or more Tasks are completed during Calendar Year 2023, but  the final Task for a requirement section \n",
       "is completed on 5/25/2024.  \n",
       "• The completion date to be recorded for the rollup Task = 12/31/2023  \n",
       "FAILS TO MEET ANNUAL CURRENCY REQUIREMENTS  (ATH 16794.51 Ch. 4, Section C)   \n",
       "When a member fails to meet annual currency requirements, their certification will lapse, and they will be placed in Required Yearly Requirement (REYR) status. A member whose certification has lapsed may participate as a \n",
       "designated trainee on an ordered pa trol. A member who fails to meet annual currency requirements for the year shall \n",
       "make up the missing hours and/or currency maintenance tasks (listed in the Task Sections on Page 1)  as a trainee, \n",
       "under the supervision of a certified coxswain the following c alendar year.   \n",
       "Coxswain shall document completion of all missing hours and/or annual currency requirements  utilizing the Task \n",
       "Sections on Page 1. Upon completion of the missing task or hours, this may serve as the form al letter from the F C to \n",
       "the OTO documenting completion.  \n",
       "1. The member has completed the missing requirement and (2) request that the member be re- instated.  \n",
       "Position:  Name: (print)  Signature:  Date:  \n",
       "Trainee:     \n",
       "Coxswain:     \n",
       "FC    \n",
       "OTO:     \n",
       "Members should keep a copy of the form for their records  \n",
       "\n",
       "**Reference 4:**    *2023 Surface Workshop Rev1*, page 35<br>  Questions & Answers About the Policies \n",
       "Night Qualification : All certified crew or coxn certified prior to 01 Jan \n",
       "2023 will be grandfathered as night operations certified. If a crew/coxn \n",
       "wishes to maintain their night certification they will need to meet the \n",
       "annual currency maintenance requirements for night certification prior to \n",
       "31 Dec 2023. Members who fail to meet these minimum requirements \n",
       "will be placed into REYR for NIGHT operations only. Meeting all other \n",
       "annual currency requirements will maintain the crew/coxn certification \n",
       "during daytime operations.  \n",
       "Response Division – 2023 Surface \n",
       "Workshop U.S COAST GUARD AUXILIARY - UNCLASSIFIED 36\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Disclaimer:** This service only contains national documents. It is for informational use only and is not intended as a substitute for official policy.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def create_long_source_list(response):\n",
    "    '''Extracts a list of sources along with full source\n",
    "\n",
    "    The dictionary has three elements (query, response, and source_documents). \n",
    "    Inside the third is a list with a custom object Document \n",
    "    associated with the key 'source_documents'\n",
    "    '''\n",
    "\n",
    "    markdown_list = []\n",
    "\n",
    "    for i, doc in enumerate(response['source_documents'], start=1):\n",
    "        page_content = doc.page_content\n",
    "        source = doc.metadata['source']\n",
    "        short_source = source.split('/')[-1].split('.')[0]\n",
    "        page = doc.metadata['page']\n",
    "        markdown_list.append(\n",
    "            f\"**Reference {i}:**    *{short_source}*, page {page}<br>  {page_content}\\n\")\n",
    "\n",
    "    long_source_list = '\\n'.join(markdown_list)\n",
    "    return long_source_list\n",
    "\n",
    "\n",
    "long_source_list = create_long_source_list(response)\n",
    "\n",
    "\n",
    "# display list\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(f\"#### **Full Source References:**\"))\n",
    "display(Markdown(long_source_list))\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(\"**Disclaimer:** This service only contains national documents. It is for informational use only and is not intended as a substitute for official policy.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08678a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c7559e",
   "metadata": {},
   "source": [
    "## 7. Evaluate the model's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14832a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get wandb Metrics-- WORKS ONLY IN JUPYTER NOTEBOOKS\n",
    "\n",
    "# %wandb wks_consulting/ChatUSCG_notebook # Display a project workspace\n",
    "\n",
    "# %wandb wks_consulting/ChatUSCG_notebook/runs/RUN_ID  # Display a single run\n",
    "\n",
    "# %wandb wks_consulting/ChatUSCG_notebook/sweeps/SWEEP_ID # Display a sweep\n",
    "\n",
    "# %wandb wks_consulting/ChatUSCG_notebook/reports/REPORT_ID # Display a report\n",
    "\n",
    "# %wandb wks_consulting/ChatUSCG_notebook -h 2048 # Specify the height of embedded iframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e79616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(config[\"model\"])\n",
    "query_tokens = encoding.encode(response['query'])\n",
    "query_length = len(query_tokens)\n",
    "source_tokens = encoding.encode(str(response['source_documents']))\n",
    "source_length = len(source_tokens)\n",
    "result_tokens = encoding.encode(response['result'])\n",
    "result_length = len(result_tokens)\n",
    "tokens = encoding.encode(str(response))\n",
    "tot_length = len(tokens)\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "    Encoding: {encoding}\n",
    "\n",
    "    {query_length} query\n",
    "    {source_length} source\n",
    "    {result_length} result\n",
    "    {tot_length} Total tokens used\n",
    "\n",
    "    GPT-3.5-turbo supports a context window of 4096 tokens\n",
    "    GPT-3.5-turbo-16k supports a context window of 16,385 tokens\n",
    "    GPT-4 supports a context window of 8192 tokens\n",
    "    GPT-4-32k supports a context window of 32,768 tokens\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "def count_tokens(response):\n",
    "    ''' counts the tokens from the response'''\n",
    "    encoding = tiktoken.encoding_for_model(config[\"model\"])\n",
    "    query_tokens = encoding.encode(response['query'])\n",
    "    query_length = len(query_tokens)\n",
    "    source_tokens = encoding.encode(str(response['source_documents']))\n",
    "    source_length = len(source_tokens)\n",
    "    result_tokens = encoding.encode(response['result'])\n",
    "    result_length = len(result_tokens)\n",
    "    tokens = encoding.encode(str(response))\n",
    "    tot_length = len(tokens)\n",
    "\n",
    "    return query_length, source_length, result_length, tot_length\n",
    "\n",
    "\n",
    "# Usage:\n",
    "response = {\n",
    "    'query': \"your_query_here\",\n",
    "    'source_documents': \"your_source_documents_here\",\n",
    "    'result': \"your_result_here\"\n",
    "}\n",
    "\n",
    "query_len, source_len, result_len, total_len = count_tokens(response)\n",
    "\n",
    "'''# use this one in python script\n",
    "wandb.log({\"tokens_used\": tot_length, \"16k context window\": \"4096 tokens\"})\n",
    "wandb.finish()  # this is only needed for the juypter notebook'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "    Encoding: {encoding}\n",
    "\n",
    "    {query_length} query\n",
    "    {source_length} source\n",
    "    {result_length} result\n",
    "    {tot_length} Total tokens used\n",
    "\n",
    "    GPT-3.5-turbo supports a context window of 4096 tokens\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write response to a pickle file, overwriting existing pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the response (a python dictionary) to a file\n",
    "import pickle\n",
    "\n",
    "with open(\"dummy_response.pkl\", \"wb\") as file:\n",
    "    pickle.dump(response, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff74ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
